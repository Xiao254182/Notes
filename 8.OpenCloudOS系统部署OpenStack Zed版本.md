#### 8.OpenCloudOS系统部署OpenStack Zed版本

1 简介

```
OpenStack 是一个开源的云计算平台，提供基础设施即服务（IaaS）的解决方案。它由一系列组件组成，包括计算、存储、网络、身份认证、编排、
计量、告警和数据库等。OpenStack可以帮助用户构建和管理私有云、公有云和混合云等多种云计算环境。 本文简要介绍 Zed 版本 OpenStack 在
本系统上的部署过程。
```

2 环境准备

2.1 拓扑介绍

基于 OpenStack 经典的三节点环境进行部署，分别是控制节点 (Controller)、计算节点 (Compute)、存储节点 (Storage)，其中存储节点一般只部
署存储服务，在资源有限的情况下，可以不单独部署该节点，把存储节点上的服务部署到计算节点即可

| ip              | 主机名     | 组件                                  |
| --------------- | ---------- | ------------------------------------- |
| 192.168.100.131 | controller | 所有组件                              |
| 192.168.100.132 | compute    | Nova, Neutron, Ceilometer             |
| 192.168.100.133 | storage    | Swift, Cinder各个节点涉及的组件如下： |

PS:控制节点内存要求不小于8G，其余节点内存要求不小于4G，存储节点的部署需要额外三块硬盘

2.2 yum源确认

OpenStack 涉及的 rpm 包大多来自OpenCloudOS系统的 EPOL 源，该源默认安装与使用，如果环境没有的用户需要手动安装

```shell
dnf install -y epol-release
```

2.3 调整主机名与映射

1 controller 节点

```shell
hostnamectl set-hostname controller
```

2 compute 节点

```shell
hostnamectl set-hostname compute
```

3 storage 节点

```shell
hostnamectl set-hostname storage
```

更新三个节点的hosts文件

```shell
[root@controller ~]# vim /etc/hosts
```

![](https://github.com/Xiao254182/notes/blob/master/img/8/1.png)

```shell
[root@controller ~]# scp /etc/hosts 192.168.100.132:/etc/hosts
The authenticity of host '192.168.100.132 (192.168.100.132)' can't be established.
ED25519 key fingerprint is SHA256:T2U3aepE7sw3pTAcTxK6pyn2DvpsiBqFYZdvvi7CGiA.
This key is not known by any other names.
Are you sure you want to continue connecting (yes/no/[fingerprint])? yes
Warning: Permanently added '192.168.100.132' (ED25519) to the list of known hosts.
root@192.168.100.132's password:
hosts                                                 100%  459   442.2KB/s   00:00
[root@controller ~]# scp /etc/hosts 192.168.100.133:/etc/hosts
The authenticity of host '192.168.100.133 (192.168.100.133)' can't be established.
ED25519 key fingerprint is SHA256:5c0qoAqnRKyqJZvmA6H82G5KIVkqZrlkJkL4JF35CZc.
This key is not known by any other names.
Are you sure you want to continue connecting (yes/no/[fingerprint])? yes
Warning: Permanently added '192.168.100.133' (ED25519) to the list of known hosts.
root@192.168.100.133's password:
hosts                                                 100%  459   604.3KB/s   00:00
```

2.4 配置时间同步

2.4.1 controller 节点

1.安装服务

```shell
[root@controller ~]# dnf install -y chrony
```

2.修改配置文件

```shell
[root@controller ~]# vim /etc/chrony.conf
```

![](https://github.com/Xiao254182/notes/blob/master/img/8/2.png)

3.重启服务

```shell
[root@controller ~]# systemctl restart chronyd
```

2.4.2 其他节点

1.安装服务

```shell
[root@compute ~]# dnf install -y chrony
[root@storage ~]# dnf install -y chrony
```

2.修改配置文件

```shell
[root@compute ~]# vim /etc/chrony.conf
[root@storage ~]# vim /etc/chrony.conf
```

![](https://github.com/Xiao254182/notes/blob/master/img/8/3.png)

3.重启服务

```shell
[root@compute ~]# systemctl restart chronyd
[root@storage ~]# systemctl restart chronyd
```

2.4.3 验证时间同步

```shell
[root@compute ~]# chronyc sources
MS Name/IP address         Stratum Poll Reach LastRx Last sample
===============================================================================
^* controller                    3   6    17    24    -72us[ -199us] +/-   50ms
[root@storage ~]# chronyc sources
MS Name/IP address         Stratum Poll Reach LastRx Last sample
===============================================================================
^* controller                    3   6    17     6  +9655ns[  +17us] +/-   56ms
```

2.5 安装数据库

```
OpenStack 中的许多服务都需要使用数据库来存储和管理数据，例如，Nova服务需要使用数据库来存储虚拟机的状态和元数据，Neutron 服务需要使用
数据库来存储网络拓扑和配置信息，Cinder 服务需要使用数据库来存储卷和快照等。在 OpenStack 中，MariaDB 通常被用作这些服务的后端数据库，
以提供高效、可靠和可扩展的数据存储和管理
```

在controller节点部署MariaDB数据库

```shell
[root@controller ~]# dnf install -y mariadb mariadb-server python3-PyMySQL
[root@controller ~]# vim /etc/my.cnf.d/openstack.cnf
[mysqld]
bind-address = 192.168.100.131
default-storage-engine = innodb
innodb_file_per_table = on
max_connections = 4096
collation-server = utf8_general_ci
character-set-server = utf8
```

![](https://github.com/Xiao254182/notes/blob/master/img/8/4.png)

```shell
[root@controller ~]# systemctl start mariadb.service && systemctl enable mariadb.service
Created symlink /etc/systemd/system/mysql.service → /usr/lib/systemd/system/mariadb.service.
Created symlink /etc/systemd/system/mysqld.service → /usr/lib/systemd/system/mariadb.service.
Created symlink /etc/systemd/system/multi-user.target.wants/mariadb.service → /usr/lib/systemd/system/mariadb.service.
```

初始化数据库

```shell
[root@controller ~]# mysql_secure_installation

NOTE: RUNNING ALL PARTS OF THIS SCRIPT IS RECOMMENDED FOR ALL MariaDB
      SERVERS IN PRODUCTION USE!  PLEASE READ EACH STEP CAREFULLY!

In order to log into MariaDB to secure it, we'll need the current
password for the root user. If you've just installed MariaDB, and
haven't set the root password yet, you should just press enter here.

Enter current password for root (enter for none):
OK, successfully used password, moving on...

Setting the root password or using the unix_socket ensures that nobody
can log into the MariaDB root user without the proper authorisation.

You already have your root account protected, so you can safely answer 'n'.

Switch to unix_socket authentication [Y/n] n
 ... skipping.

You already have your root account protected, so you can safely answer 'n'.

Change the root password? [Y/n] y
New password:
Re-enter new password:
Password updated successfully!
Reloading privilege tables..
 ... Success!


By default, a MariaDB installation has an anonymous user, allowing anyone
to log into MariaDB without having to have a user account created for
them.  This is intended only for testing, and to make the installation
go a bit smoother.  You should remove them before moving into a
production environment.

Remove anonymous users? [Y/n] y
 ... Success!

Normally, root should only be allowed to connect from 'localhost'.  This
ensures that someone cannot guess at the root password from the network.

Disallow root login remotely? [Y/n] n
 ... skipping.

By default, MariaDB comes with a database named 'test' that anyone can
access.  This is also intended only for testing, and should be removed
before moving into a production environment.

Remove test database and access to it? [Y/n] y
 - Dropping test database...
 ... Success!
 - Removing privileges on test database...
 ... Success!

Reloading the privilege tables will ensure that all changes made so far
will take effect immediately.

Reload privilege tables now? [Y/n] y
 ... Success!

Cleaning up...

All done!  If you've completed all of the above steps, your MariaDB
installation should now be secure.

Thanks for using MariaDB!
```

2.6 安装消息队列

```
OpenStack 使用消息队列在各个服务之间传递和处理消息，一般使用 RabbitMQ 来实现此功能。
```

在controller节点部署RabbitMQ消息队列

```shell
[root@controller ~]# dnf install -y rabbitmq-server
[root@controller ~]# systemctl start rabbitmq-server.service && systemctl enable rabbitmq-server.service
Created symlink /etc/systemd/system/multi-user.target.wants/rabbitmq-server.service → /usr/lib/systemd/system/rabbitmq-server.service.
```

配置OpenStack用户,其中“000000”是OpenStack服务登录消息队列的密码，下文各个服务几乎都会用到，务必要保持一致

```shell
[root@controller ~]# rabbitmqctl add_user openstack 000000
Adding user "openstack" ...
Done. Don't forget to grant the user permissions to some virtual hosts! See 'rabbitmqctl help set_permissions' to learn more.
```

设置 OpenStack 用户权限，允许进行配置、写、读

```shell
[root@controller ~]# rabbitmqctl set_permissions openstack ".*" ".*" ".*"
Setting permissions for user "openstack" in vhost "/" ...
```

2.7 安装内存对象缓存服务

```
在 OpenStack 中，通常使用 Memcached 作为 Keystone 服务的缓存层，以提高身份验证和授权的性能和可扩展性。Keystone 服务需要频繁地访问
数据库来验证用户身份和授权访问权限，使用 Memcached 缓存可以减少对数据库的访问次数，从而提高 Keystone 服务的性能和可靠性。
```

在controller节点安装Memcached服务

```shell
[root@controller ~]# dnf install -y memcached python3-memcached
[root@controller ~]# vim /etc/sysconfig/memcached
```

![](https://github.com/Xiao254182/notes/blob/master/img/8/5.png)

```shell
[root@controller ~]# systemctl start memcached.service && systemctl enable memcached.service
Created symlink /etc/systemd/system/multi-user.target.wants/memcached.service → /usr/lib/systemd/system/memcached.service.
```

验证服务

```shell
[root@controller ~]# memcached-tool controller stats
#controller:11211       Field         Value
              accepting_conns             1
                    auth_cmds             0
                  auth_errors             0
                        bytes             0
                   bytes_read             7
                bytes_written             0
                   cas_badval             0
                     cas_hits             0
                   cas_misses             0
                    cmd_flush             0
                      cmd_get             0
                     cmd_meta             0
                      cmd_set             0
                    cmd_touch             0
                  conn_yields             0
        connection_structures             4
        crawler_items_checked             0
            crawler_reclaimed             0
             curr_connections             3
                   curr_items             0
                    decr_hits             0
                  decr_misses             0
                  delete_hits             0
                delete_misses             0
              direct_reclaims             0
               evicted_active             0
            evicted_unfetched             0
                    evictions             0
            expired_unfetched             0
                  get_expired             0
                  get_flushed             0
                     get_hits             0
                   get_misses             0
                   hash_bytes        524288
            hash_is_expanding             0
             hash_power_level            16
                    incr_hits             0
                  incr_misses             0
                     libevent 2.1.12-stable
               limit_maxbytes      67108864
          listen_disabled_num             0
             log_watcher_sent             0
          log_watcher_skipped             0
                 log_watchers             0
           log_worker_dropped             0
           log_worker_written             0
            lru_bumps_dropped             0
          lru_crawler_running             0
           lru_crawler_starts             1
       lru_maintainer_juggles            92
            lrutail_reflocked             0
                 malloc_fails             0
              max_connections          1024
                moves_to_cold             0
                moves_to_warm             0
             moves_within_lru             0
                          pid         40432
                 pointer_size            64
               read_buf_bytes         32768
          read_buf_bytes_free             0
               read_buf_count             2
                 read_buf_oom             0
                    reclaimed             0
         rejected_connections             0
                 reserved_fds            20
           response_obj_bytes         16384
           response_obj_count             1
             response_obj_oom             0
         round_robin_fallback             0
                rusage_system      0.025525
                  rusage_user      0.009404
        slab_global_page_pool             0
   slab_reassign_busy_deletes             0
     slab_reassign_busy_items             0
  slab_reassign_chunk_rescues             0
slab_reassign_evictions_nomem             0
 slab_reassign_inline_reclaim             0
        slab_reassign_rescues             0
        slab_reassign_running             0
                  slabs_moved             0
              store_no_memory             0
              store_too_large             0
                      threads             4
                         time    1721792323
   time_in_listen_disabled_us             0
            total_connections             4
                  total_items             0
                   touch_hits             0
                 touch_misses             0
          unexpected_napi_ids             0
                       uptime            43
                      version        1.6.22
```

3.部署OpenStack

3.1 安装Keystone

```
Keystone 是 OpenStack 核心组件，用于身份认证和授权。它提供了一个中央身份管理系统，可以管理 OpenStack中 的用户、角色和服务等
```

1.在controller节点安装Keystone

```shell
[root@controller ~]# dnf install -y openstack-keystone httpd mod_wsgi python3-openstackclient
```

2.创建 Keystone 数据库并授权，其中“000000”为 Keystone 数据库密码

```shell
[root@controller ~]# mysql -uroot -p000000
Welcome to the MariaDB monitor.  Commands end with ; or \g.
Your MariaDB connection id is 10
Server version: 10.11.4-MariaDB MariaDB Server

Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

MariaDB [(none)]> create database keystone;
Query OK, 1 row affected (0.000 sec)

MariaDB [(none)]> grant all privileges on keystone.* to 'keystone'@'localhost' identified by '000000';
Query OK, 0 rows affected (0.001 sec)

MariaDB [(none)]> grant all privileges on keystone.* to 'keystone'@'%' identified by '000000';
Query OK, 0 rows affected (0.001 sec)

MariaDB [(none)]> exit
Bye
```

3.配置Keystone

```shell
[root@controller ~]# vim /etc/keystone/keystone.conf
[database]
connection = mysql+pymysql://keystone:000000@controller/keystone

[token]
provider = fernet
```

![](https://github.com/Xiao254182/notes/blob/master/img/8/6.png)  

![](https://github.com/Xiao254182/notes/blob/master/img/8/7.png)

4.同步数据库

```shell
[root@controller ~]# su -s /bin/sh -c "keystone-manage db_sync" keystone
2024-07-24 11:51:23.113 49519 INFO alembic.runtime.migration [-] Context impl MySQLImpl.
2024-07-24 11:51:23.113 49519 INFO alembic.runtime.migration [-] Will assume non-transactional DDL.
2024-07-24 11:51:23.124 49519 INFO alembic.runtime.migration [-] Context impl MySQLImpl.
2024-07-24 11:51:23.125 49519 INFO alembic.runtime.migration [-] Will assume non-transactional DDL.
2024-07-24 11:51:23.139 49519 INFO alembic.runtime.migration [-] Running upgrade  -> 27e647c0fad4, Initial version
2024-07-24 11:51:23.415 49519 INFO alembic.runtime.migration [-] Running upgrade 27e647c0fad4 -> e25ffa003242, Initial no-op Yoga contract migration.
2024-07-24 11:51:23.416 49519 INFO alembic.runtime.migration [-] Running upgrade 27e647c0fad4 -> 29e87d24a316, Initial no-op Yoga expand migration.
```

5.初始化Fernet密钥仓库

```shell
[root@controller ~]# keystone-manage fernet_setup --keystone-user keystone --keystone-group keystone
2024-07-24 11:52:47.089 50592 INFO keystone.common.utils [-] /etc/keystone/fernet-keys/ does not appear to exist; attempting to create it
2024-07-24 11:52:47.090 50592 INFO keystone.common.fernet_utils [-] Created a new temporary key: /etc/keystone/fernet-keys/0.tmp
2024-07-24 11:52:47.090 50592 INFO keystone.common.fernet_utils [-] Become a valid new key: /etc/keystone/fernet-keys/0
2024-07-24 11:52:47.090 50592 INFO keystone.common.fernet_utils [-] Starting key rotation with 1 key files: ['/etc/keystone/fernet-keys/0']
2024-07-24 11:52:47.090 50592 INFO keystone.common.fernet_utils [-] Created a new temporary key: /etc/keystone/fernet-keys/0.tmp
2024-07-24 11:52:47.091 50592 INFO keystone.common.fernet_utils [-] Current primary key is: 0
2024-07-24 11:52:47.091 50592 INFO keystone.common.fernet_utils [-] Next primary key will be: 1
2024-07-24 11:52:47.091 50592 INFO keystone.common.fernet_utils [-] Promoted key 0 to be the primary: 1
2024-07-24 11:52:47.091 50592 INFO keystone.common.fernet_utils [-] Become a valid new key: /etc/keystone/fernet-keys/0
[root@controller ~]# keystone-manage credential_setup --keystone-user keystone --keystone-group keystone
2024-07-24 11:53:00.213 50673 INFO keystone.common.utils [-] /etc/keystone/credential-keys/ does not appear to exist; attempting to create it
2024-07-24 11:53:00.214 50673 INFO keystone.common.fernet_utils [-] Created a new temporary key: /etc/keystone/credential-keys/0.tmp
2024-07-24 11:53:00.214 50673 INFO keystone.common.fernet_utils [-] Become a valid new key: /etc/keystone/credential-keys/0
2024-07-24 11:53:00.214 50673 INFO keystone.common.fernet_utils [-] Starting key rotation with 1 key files: ['/etc/keystone/credential-keys/0']
2024-07-24 11:53:00.214 50673 INFO keystone.common.fernet_utils [-] Created a new temporary key: /etc/keystone/credential-keys/0.tmp
2024-07-24 11:53:00.214 50673 INFO keystone.common.fernet_utils [-] Current primary key is: 0
2024-07-24 11:53:00.214 50673 INFO keystone.common.fernet_utils [-] Next primary key will be: 1
2024-07-24 11:53:00.214 50673 INFO keystone.common.fernet_utils [-] Promoted key 0 to be the primary: 1
2024-07-24 11:53:00.215 50673 INFO keystone.common.fernet_utils [-] Become a valid new key: /etc/keystone/credential-keys/0
```

6.启动服务，为admin用户设置密码

```shell
[root@controller ~]# keystone-manage bootstrap --bootstrap-password 000000 \
--bootstrap-admin-url http://controller:5000/v3/ \
--bootstrap-internal-url http://controller:5000/v3/ \
--bootstrap-public-url http://controller:5000/v3/ \
--bootstrap-region-id RegionOne
2024-07-24 11:54:58.996 51961 INFO keystone.cmd.bootstrap [None req-fc045807-3745-4dea-bbb4-df8aa3bde484 - - - - - -] Created domain default
2024-07-24 11:54:59.027 51961 INFO keystone.cmd.bootstrap [None req-fc045807-3745-4dea-bbb4-df8aa3bde484 - - - - - -] Created project admin
2024-07-24 11:54:59.241 51961 INFO keystone.cmd.bootstrap [None req-fc045807-3745-4dea-bbb4-df8aa3bde484 - - - - - -] Created user admin
2024-07-24 11:54:59.248 51961 INFO keystone.cmd.bootstrap [None req-fc045807-3745-4dea-bbb4-df8aa3bde484 - - - - - -] Created role reader
2024-07-24 11:54:59.254 51961 INFO keystone.cmd.bootstrap [None req-fc045807-3745-4dea-bbb4-df8aa3bde484 - - - - - -] Created role member
2024-07-24 11:54:59.264 51961 INFO keystone.cmd.bootstrap [None req-fc045807-3745-4dea-bbb4-df8aa3bde484 - - - - - -] Created implied role where fc32535486524f0c9b60e48f4c3e25f5 implies 555a4d2384ee4da3965ea391eebdac73
2024-07-24 11:54:59.269 51961 INFO keystone.cmd.bootstrap [None req-fc045807-3745-4dea-bbb4-df8aa3bde484 - - - - - -] Created role admin
2024-07-24 11:54:59.277 51961 INFO keystone.cmd.bootstrap [None req-fc045807-3745-4dea-bbb4-df8aa3bde484 - - - - - -] Created implied role where d736f2090f0f44a799d488115fad5594 implies fc32535486524f0c9b60e48f4c3e25f5
2024-07-24 11:54:59.289 51961 INFO keystone.cmd.bootstrap [None req-fc045807-3745-4dea-bbb4-df8aa3bde484 - - - - - -] Granted role admin on project admin to user admin.
2024-07-24 11:54:59.295 51961 INFO keystone.cmd.bootstrap [None req-fc045807-3745-4dea-bbb4-df8aa3bde484 - - - - - -] Granted role admin on the system to user admin.
2024-07-24 11:54:59.301 51961 WARNING py.warnings [None req-fc045807-3745-4dea-bbb4-df8aa3bde484 - - - - - -] /usr/lib/python3.11/site-packages/pycadf/identifier.py:71: UserWarning: Invalid uuid: RegionOne. To ensure interoperability, identifiers should be a valid uuid.
  warnings.warn(('Invalid uuid: %s. To ensure interoperability, '

2024-07-24 11:54:59.303 51961 INFO keystone.cmd.bootstrap [None req-fc045807-3745-4dea-bbb4-df8aa3bde484 - - - - - -] Created region RegionOne
2024-07-24 11:54:59.318 51961 INFO keystone.cmd.bootstrap [None req-fc045807-3745-4dea-bbb4-df8aa3bde484 - - - - - -] Created public endpoint http://controller:5000/v3/
2024-07-24 11:54:59.326 51961 INFO keystone.cmd.bootstrap [None req-fc045807-3745-4dea-bbb4-df8aa3bde484 - - - - - -] Created internal endpoint http://controller:5000/v3/
2024-07-24 11:54:59.336 51961 INFO keystone.cmd.bootstrap [None req-fc045807-3745-4dea-bbb4-df8aa3bde484 - - - - - -] Created admin endpoint http://controller:5000/v3/
```

7.配置HTTP server

```shell
[root@controller ~]# vim /etc/httpd/conf/httpd.conf
```

![](https://github.com/Xiao254182/notes/blob/master/img/8/8.png)

8.创建软连接

```shell
[root@controller ~]# ln -s /usr/share/keystone/wsgi-keystone.conf /etc/httpd/conf.d/
```

9.设置开机启动，并开启服务

```shell
[root@controller ~]# systemctl start httpd.service && systemctl enable httpd.service
Created symlink /etc/systemd/system/multi-user.target.wants/httpd.service → /usr/lib/systemd/system/httpd.service.
```

10.创建环境变量配置

```shell
[root@controller ~]# cat << EOF >> ~/.admin-openrc
export OS_PROJECT_DOMAIN_NAME=Default
export OS_USER_DOMAIN_NAME=Default
export OS_PROJECT_NAME=admin
export OS_USERNAME=admin
export OS_PASSWORD=000000
export OS_AUTH_URL=http://controller:5000/v3
export OS_IDENTITY_API_VERSION=3
export OS_IMAGE_API_VERSION=2
EOF
```

11.依次创建domain,projects,users,roles

导入环境变量

```shell
[root@controller ~]# source ~/.admin-openrc
```

创建一个名为example的domain

```shell
[root@controller ~]# openstack domain create --description "An Example Domain" example
+-------------+----------------------------------+
| Field       | Value                            |
+-------------+----------------------------------+
| description | An Example Domain                |
| enabled     | True                             |
| id          | bd20bf148b0649edb1e5fe434c8b5936 |
| name        | example                          |
| options     | {}                               |
| tags        | []                               |
+-------------+----------------------------------+
```

创建一个名为service的project

```shell
[root@controller ~]# openstack project create --domain default --description "Service Project" service
+-------------+----------------------------------+
| Field       | Value                            |
+-------------+----------------------------------+
| description | Service Project                  |
| domain_id   | default                          |
| enabled     | True                             |
| id          | 5622ebccc3ec4b4ab2d73ef6564cb27d |
| is_domain   | False                            |
| name        | service                          |
| options     | {}                               |
| parent_id   | default                          |
| tags        | []                               |
+-------------+----------------------------------+
```

创建（non-admin）project `myproject`，user `myuser` 和 role `myrole`，为 `myproject` 和 `myuser` 添加角色`myrole`

```shell
[root@controller ~]# openstack project create --domain default --description "Demo Project" myproject
+-------------+----------------------------------+
| Field       | Value                            |
+-------------+----------------------------------+
| description | Demo Project                     |
| domain_id   | default                          |
| enabled     | True                             |
| id          | c06de4e30ef04995a642b5022abf1654 |
| is_domain   | False                            |
| name        | myproject                        |
| options     | {}                               |
| parent_id   | default                          |
| tags        | []                               |
+-------------+----------------------------------+
[root@controller ~]# openstack user create --domain default --password-prompt myuser
User Password:
Repeat User Password:
+---------------------+----------------------------------+
| Field               | Value                            |
+---------------------+----------------------------------+
| domain_id           | default                          |
| enabled             | True                             |
| id                  | 16188e0ff1834da399525cce2b1989c9 |
| name                | myuser                           |
| options             | {}                               |
| password_expires_at | None                             |
+---------------------+----------------------------------+
[root@controller ~]# openstack role create myrole
+-------------+----------------------------------+
| Field       | Value                            |
+-------------+----------------------------------+
| description | None                             |
| domain_id   | None                             |
| id          | fdab49e9a39a4e3f87053bd3f1334310 |
| name        | myrole                           |
| options     | {}                               |
+-------------+----------------------------------+
[root@controller ~]# openstack role add --project myproject --user myuser myrole
```

(PS:注：包括下文中遇到--password-prompt的步骤都是需要用户来设置密码，部署过程一定要保证这些密码与配置文件中的一致)

12 验证

取消临时环境变量OS_AUTH_URL和OS_PASSWORD：

```shell
[root@controller ~]# source ~/.admin-openrc
[root@controller ~]# unset OS_AUTH_URL OS_PASSWORD
```

为admin用户请求token:

```shell
[root@controller ~]# openstack --os-auth-url http://controller:5000/v3 \
--os-project-domain-name Default --os-user-domain-name Default \
--os-project-name admin --os-username admin token issue
Password:
+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Field      | Value                                                                                                                                                                                   |
+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| expires    | 2024-07-24T06:00:48+0000                                                                                                                                                                |
| id         | gAAAAABmoIqAJ997LMaxJGBV4ldHGKeiR4mKtwCBEt7UK9ktGrDzh1H3sdYX0rO7r6BEm7N1BybGEjXln9mCPL_Z4ExNEh5HAcRlST0NhLRwgWXUJ55XJHU1oW9xoAeq3tx64-AUyGrilwWyo0RjPINIOs9jdmeqoPoIdb-d4VaAS_fhzqqTu-o |
| project_id | 340528fdeedf40eb8384e05b3bd67e74                                                                                                                                                        |
| user_id    | f8b9c2330d4240a0bafdcd0e886ed343                                                                                                                                                        |
+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
```

为myuser用户请求token:

```shell
[root@controller ~]# openstack --os-auth-url http://controller:5000/v3 \
--os-project-domain-name Default --os-user-domain-name Default \
--os-project-name myproject --os-username myuser token issue
Password:
+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Field      | Value                                                                                                                                                                                   |
+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| expires    | 2024-07-24T06:01:04+0000                                                                                                                                                                |
| id         | gAAAAABmoIqQDIH7pOHjlpKBwjHAxJWHcvtg5yWyWD5OSYo2fn3c2iC7LNzcddpSmMJDSCMJgsmZVKcXyIPCQzC_5f4hrAtUahQw15kjvuhBLzrLVG_cOtlO5vOGKnszi3NYWFXI8_5gWf2_X800fsD9xsZ9oqbnIv7BeHAwpr9G51r0Klbbmeo |
| project_id | c06de4e30ef04995a642b5022abf1654                                                                                                                                                        |
| user_id    | 16188e0ff1834da399525cce2b1989c9                                                                                                                                                        |
+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
```

3.2 安装Glance

```
Glance 是 OpenStack 的一个组件，提供了一个中央镜像管理系统，可以管理 OpenStack 中的虚拟机镜像
```

在controller节点部署Glance

1.安装软件包

```shell
[root@controller ~]# dnf install -y openstack-glance
```

2 创建 Glance 数据库并授权

```shell
[root@controller ~]# mysql -uroot -p000000
Welcome to the MariaDB monitor.  Commands end with ; or \g.
Your MariaDB connection id is 24
Server version: 10.11.4-MariaDB MariaDB Server

Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

MariaDB [(none)]> create database glance;
Query OK, 1 row affected (0.001 sec)

MariaDB [(none)]> grant all privileges on glance.* to 'glance'@'localhost' identified by '000000';
Query OK, 0 rows affected (0.001 sec)

MariaDB [(none)]> grant all privileges on glance.* to 'glance'@'%' identified by '000000';
Query OK, 0 rows affected (0.001 sec)

MariaDB [(none)]> exit
Bye
```

3.创建用户

```shell
[root@controller ~]# source ~/.admin-openrc
[root@controller ~]# openstack user create --domain default --password-prompt glance
User Password:
Repeat User Password:
+---------------------+----------------------------------+
| Field               | Value                            |
+---------------------+----------------------------------+
| domain_id           | default                          |
| enabled             | True                             |
| id                  | 8e4dd67d849f4826b8d8361ee64ad74e |
| name                | glance                           |
| options             | {}                               |
| password_expires_at | None                             |
+---------------------+----------------------------------+
```

4.添加 Glance 用户到 service project 并指定 admin 的 role

```shell
[root@controller ~]# openstack role add --project service --user glance admin
```

5.创建 Glance 服务实体

```shell
[root@controller ~]# openstack service create --name glance --description "OpenStack Image" image
+-------------+----------------------------------+
| Field       | Value                            |
+-------------+----------------------------------+
| description | OpenStack Image                  |
| enabled     | True                             |
| id          | 7879d84ce7ee4ab78f778c1e69d6fbd9 |
| name        | glance                           |
| type        | image                            |
+-------------+----------------------------------+
```

6.创建镜像服务API端点

```shell
[root@controller ~]# openstack endpoint create --region RegionOne image public http://controller:9292
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | 4d9711392466488598b5892d16dd998c |
| interface    | public                           |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | 7879d84ce7ee4ab78f778c1e69d6fbd9 |
| service_name | glance                           |
| service_type | image                            |
| url          | http://controller:9292           |
+--------------+----------------------------------+
[root@controller ~]# openstack endpoint create --region RegionOne image internal http://controller:9292
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | 1f3c7ec51fc344e9b6d0dc5988d3d94e |
| interface    | internal                         |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | 7879d84ce7ee4ab78f778c1e69d6fbd9 |
| service_name | glance                           |
| service_type | image                            |
| url          | http://controller:9292           |
+--------------+----------------------------------+
[root@controller ~]# openstack endpoint create --region RegionOne image admin http://controller:9292
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | 649398bf7f184effa94bf7da12a1327c |
| interface    | admin                            |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | 7879d84ce7ee4ab78f778c1e69d6fbd9 |
| service_name | glance                           |
| service_type | image                            |
| url          | http://controller:9292           |
+--------------+----------------------------------+
```

7.编辑 Glance 配置文件

```shell
[root@controller ~]# vim /etc/glance/glance-api.conf
[database]
connection = mysql+pymysql://glance:000000@controller/glance

[keystone_authtoken]
www_authenticate_uri  = http://controller:5000
auth_url = http://controller:5000
memcached_servers = controller:11211
auth_type = password
project_domain_name = Default
user_domain_name = Default
project_name = service
username = glance
password = 000000

[paste_deploy]
flavor = keystone

[glance_store]
stores = file,http
default_store = file
filesystem_store_datadir = /var/lib/glance/images/
```

![](https://github.com/Xiao254182/notes/blob/master/img/8/9.png)

![](https://github.com/Xiao254182/notes/blob/master/img/8/10.png)

![](https://github.com/Xiao254182/notes/blob/master/img/8/11.png)

![](https://github.com/Xiao254182/notes/blob/master/img/8/12.png)

8.同步数据库

```shell
[root@controller ~]# su -s /bin/sh -c "glance-manage db_sync" glance
2024-07-24 13:18:16.498 107431 INFO alembic.runtime.migration [-] Context impl MySQLImpl.
2024-07-24 13:18:16.499 107431 INFO alembic.runtime.migration [-] Will assume non-transactional DDL.
2024-07-24 13:18:16.506 107431 INFO alembic.runtime.migration [-] Context impl MySQLImpl.
2024-07-24 13:18:16.506 107431 INFO alembic.runtime.migration [-] Will assume non-transactional DDL.
INFO  [alembic.runtime.migration] Context impl MySQLImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
INFO  [alembic.runtime.migration] Running upgrade  -> liberty, liberty initial
INFO  [alembic.runtime.migration] Running upgrade liberty -> mitaka01, add index on created_at and updated_at columns of 'images' table
INFO  [alembic.runtime.migration] Running upgrade mitaka01 -> mitaka02, update metadef os_nova_server
INFO  [alembic.runtime.migration] Running upgrade mitaka02 -> ocata_expand01, add visibility to images
INFO  [alembic.runtime.migration] Running upgrade ocata_expand01 -> pike_expand01, empty expand for symmetry with pike_contract01
INFO  [alembic.runtime.migration] Running upgrade pike_expand01 -> queens_expand01
INFO  [alembic.runtime.migration] Running upgrade queens_expand01 -> rocky_expand01, add os_hidden column to images table
INFO  [alembic.runtime.migration] Running upgrade rocky_expand01 -> rocky_expand02, add os_hash_algo and os_hash_value columns to images table
INFO  [alembic.runtime.migration] Running upgrade rocky_expand02 -> train_expand01, empty expand for symmetry with train_contract01
INFO  [alembic.runtime.migration] Running upgrade train_expand01 -> ussuri_expand01, empty expand for symmetry with ussuri_expand01
INFO  [alembic.runtime.migration] Running upgrade ussuri_expand01 -> wallaby_expand01, add image_id, request_id, user columns to tasks table"
INFO  [alembic.runtime.migration] Context impl MySQLImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
Upgraded database to: wallaby_expand01, current revision(s): wallaby_expand01
INFO  [alembic.runtime.migration] Context impl MySQLImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
INFO  [alembic.runtime.migration] Context impl MySQLImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
Database migration is up to date. No migration needed.
INFO  [alembic.runtime.migration] Context impl MySQLImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
INFO  [alembic.runtime.migration] Context impl MySQLImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
INFO  [alembic.runtime.migration] Running upgrade mitaka02 -> ocata_contract01, remove is_public from images
INFO  [alembic.runtime.migration] Running upgrade ocata_contract01 -> pike_contract01, drop glare artifacts tables
INFO  [alembic.runtime.migration] Running upgrade pike_contract01 -> queens_contract01
INFO  [alembic.runtime.migration] Running upgrade queens_contract01 -> rocky_contract01
INFO  [alembic.runtime.migration] Running upgrade rocky_contract01 -> rocky_contract02
INFO  [alembic.runtime.migration] Running upgrade rocky_contract02 -> train_contract01
INFO  [alembic.runtime.migration] Running upgrade train_contract01 -> ussuri_contract01
INFO  [alembic.runtime.migration] Running upgrade ussuri_contract01 -> wallaby_contract01
INFO  [alembic.runtime.migration] Context impl MySQLImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
Upgraded database to: wallaby_contract01, current revision(s): wallaby_contract01
INFO  [alembic.runtime.migration] Context impl MySQLImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
Database is synced successfully.
```

9.启动服务

```shell
[root@controller ~]# systemctl start openstack-glance-api.service && systemctl enable openstack-glance-api.service
Created symlink /etc/systemd/system/multi-user.target.wants/openstack-glance-api.service → /usr/lib/systemd/system/openstack-glance-api.service.
```

10.验证

下载镜像

```shell
x86镜像下载：
wget http://download.cirros-cloud.net/0.4.0/cirros-0.4.0-x86_64-disk.img

arm镜像下载：
wget http://download.cirros-cloud.net/0.4.0/cirros-0.4.0-aarch64-disk.img
```

向Image服务上传镜像

```shell
[root@controller ~]# openstack image create --disk-format qcow2 --container-format bare --file cirros-0.4.0-x86_64-disk.img --public cirros
+------------------+--------------------------------------------------------------------------------------------------------------------------------------------+
| Field            | Value                                                                                                                                      |
+------------------+--------------------------------------------------------------------------------------------------------------------------------------------+
| container_format | bare                                                                                                                                       |
| created_at       | 2024-07-24T05:24:36Z                                                                                                                       |
| disk_format      | qcow2                                                                                                                                      |
| file             | /v2/images/c94f006b-ee15-4f1e-8b6f-df7ffb81ee84/file                                                                                       |
| id               | c94f006b-ee15-4f1e-8b6f-df7ffb81ee84                                                                                                       |
| min_disk         | 0                                                                                                                                          |
| min_ram          | 0                                                                                                                                          |
| name             | cirros                                                                                                                                     |
| owner            | 340528fdeedf40eb8384e05b3bd67e74                                                                                                           |
| properties       | os_hidden='False', owner_specified.openstack.md5='', owner_specified.openstack.object='images/cirros', owner_specified.openstack.sha256='' |
| protected        | False                                                                                                                                      |
| schema           | /v2/schemas/image                                                                                                                          |
| status           | queued                                                                                                                                     |
| tags             |                                                                                                                                            |
| updated_at       | 2024-07-24T05:24:36Z                                                                                                                       |
| visibility       | public                                                                                                                                     |
+------------------+--------------------------------------------------------------------------------------------------------------------------------------------+
```

确认镜像上传并验证属性

```shell
[root@controller ~]# openstack image list
+--------------------------------------+--------+--------+
| ID                                   | Name   | Status |
+--------------------------------------+--------+--------+
| c94f006b-ee15-4f1e-8b6f-df7ffb81ee84 | cirros | active |
+--------------------------------------+--------+--------+
```

3.3 Placement 安装

```
Placement 是 OpenStack 的一个组件，它提供了一个中央资源管理系统，用于资源调度和分配，可以管理 OpenStack 中的计算、存储和网络资源
```

在controller节点部署Placement

1.安装软件包

```shell
[root@controller ~]# dnf install -y openstack-placement-api
```

2.创建 Placement 数据库

```shell
[root@controller ~]# mysql -uroot -p000000
Welcome to the MariaDB monitor.  Commands end with ; or \g.
Your MariaDB connection id is 30
Server version: 10.11.4-MariaDB MariaDB Server

Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

MariaDB [(none)]> create database placement;
Query OK, 1 row affected (0.001 sec)

MariaDB [(none)]> grant all privileges on placement.* to 'placement'@'localhost' identified by '000000';
Query OK, 0 rows affected (0.001 sec)

MariaDB [(none)]> grant all privileges on placement.* to 'placement'@'%' identified by '000000';
Query OK, 0 rows affected (0.001 sec)

MariaDB [(none)]> exit
Bye
```

3.创建用户

```shell
[root@controller ~]# source ~/.admin-openrc
[root@controller ~]# openstack user create --domain default --password-prompt placement
User Password:
Repeat User Password:
+---------------------+----------------------------------+
| Field               | Value                            |
+---------------------+----------------------------------+
| domain_id           | default                          |
| enabled             | True                             |
| id                  | 1f36b346c15d4b75888ed03e91612104 |
| name                | placement                        |
| options             | {}                               |
| password_expires_at | None                             |
+---------------------+----------------------------------+
```

4.添加 Placement 用户到 service project 并指定 admin 的 role

```shell
[root@controller ~]# openstack role add --project service --user placement admin
```

5.创建 Placement 服务实体

```shell
[root@controller ~]# openstack service create --name placement --description "Placement API" placement
+-------------+----------------------------------+
| Field       | Value                            |
+-------------+----------------------------------+
| description | Placement API                    |
| enabled     | True                             |
| id          | e64020e958864792b4de1d08f27559c3 |
| name        | placement                        |
| type        | placement                        |
+-------------+----------------------------------+
```

6.创建 Placement 服务 API 端点

```shell
[root@controller ~]# openstack endpoint create --region RegionOne placement public http://controller:8778
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | 96ad37c99ab4433297dc231370317c9f |
| interface    | public                           |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | e64020e958864792b4de1d08f27559c3 |
| service_name | placement                        |
| service_type | placement                        |
| url          | http://controller:8778           |
+--------------+----------------------------------+
[root@controller ~]# openstack endpoint create --region RegionOne placement internal http://controller:8778
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | 9812530b61634a92b16b9235c7b138c8 |
| interface    | internal                         |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | e64020e958864792b4de1d08f27559c3 |
| service_name | placement                        |
| service_type | placement                        |
| url          | http://controller:8778           |
+--------------+----------------------------------+
[root@controller ~]# openstack endpoint create --region RegionOne placement admin http://controller:8778
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | b965e68e44b9458dbc27a82d7ca18e00 |
| interface    | admin                            |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | e64020e958864792b4de1d08f27559c3 |
| service_name | placement                        |
| service_type | placement                        |
| url          | http://controller:8778           |
+--------------+----------------------------------+
```

7.编辑 Placement 配置文件

```shell
[root@controller ~]# vim /etc/placement/placement.conf
[placement_database]
connection = mysql+pymysql://placement:000000@controller/placement

[api]
auth_strategy = keystone

[keystone_authtoken]
auth_url = http://controller:5000/v3
memcached_servers = controller:11211
auth_type = password
project_domain_name = Default
user_domain_name = Default
project_name = service
username = placement
password = 000000
```

![](https://github.com/Xiao254182/notes/blob/master/img/8/13.png)

![](https://github.com/Xiao254182/notes/blob/master/img/8/14.png)

![](https://github.com/Xiao254182/notes/blob/master/img/8/15.png)

8.同步数据库

```shell
[root@controller ~]# su -s /bin/sh -c "placement-manage db sync" placement
```

9.重启 httpd 服务

```shell
[root@controller ~]# systemctl restart httpd
```

10.验证

执行状态检查：

```shell
[root@controller ~]# source ~/.admin-openrc
[root@controller ~]# placement-status upgrade check
+----------------------------------------------------------------------+
| Upgrade Check Results                                                |
+----------------------------------------------------------------------+
| Check: Missing Root Provider IDs                                     |
| Result: Success                                                      |
| Details: None                                                        |
+----------------------------------------------------------------------+
| Check: Incomplete Consumers                                          |
| Result: Success                                                      |
| Details: None                                                        |
+----------------------------------------------------------------------+
| Check: Policy File JSON to YAML Migration                            |
| Result: Failure                                                      |
| Details: Your policy file is JSON-formatted which is deprecated. You |
|   need to switch to YAML-formatted file. Use the                     |
|   ``oslopolicy-convert-json-to-yaml`` tool to convert the            |
|   existing JSON-formatted files to YAML in a backwards-              |
|   compatible manner: https://docs.openstack.org/oslo.policy/         |
|   latest/cli/oslopolicy-convert-json-to-yaml.html.                   |
+----------------------------------------------------------------------+
```

验证 Placement API 运行命令：

安装osc-placement插件：

```shell
[root@controller ~]# dnf install -y python3-osc-placement
```

列出可用的资源类别及特性：

```shell
[root@controller ~]# openstack --os-placement-api-version 1.2 resource class list --sort-column name
[root@controller ~]# openstack --os-placement-api-version 1.6 trait list --sort-column name
```

3.4 Nova 安装

```
Nova 是 OpenStack 的一个组件，提供了一个中央计算管理系统，用于管理计算资源。它可以管理OpenStack中的虚拟机实例、网络和存储等资源
```

在controller节点和compute节点部署Nova

3.4.1 controller节点

1.安装软件包

```shell
[root@controller ~]# dnf install -y openstack-nova-api openstack-nova-conductor openstack-nova-novncproxy openstack-nova-scheduler
```

2.创建 Nova 数据库并授权

```shell
[root@controller ~]# mysql -uroot -p000000
Welcome to the MariaDB monitor.  Commands end with ; or \g.
Your MariaDB connection id is 41
Server version: 10.11.4-MariaDB MariaDB Server

Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

MariaDB [(none)]> create database nova_api;
Query OK, 1 row affected (0.000 sec)

MariaDB [(none)]> create database nova;
Query OK, 1 row affected (0.000 sec)

MariaDB [(none)]> create database nova_cell0;
Query OK, 1 row affected (0.000 sec)

MariaDB [(none)]> grant all privileges on nova_api.* to 'nova'@'localhost' identified by '000000';
Query OK, 0 rows affected (0.001 sec)

MariaDB [(none)]> grant all privileges on nova_api.* to 'nova'@'%' identified by '000000';
Query OK, 0 rows affected (0.001 sec)

MariaDB [(none)]> grant all privileges on nova.* to 'nova'@'localhost' identified by '000000';
Query OK, 0 rows affected (0.001 sec)

MariaDB [(none)]> grant all privileges on nova.* to 'nova'@'%' identified by '000000';  Query OK, 0 rows affected (0.001 sec)

MariaDB [(none)]> grant all privileges on nova_cell0.* to 'nova'@'localhost' identified
by '000000';
Query OK, 0 rows affected (0.001 sec)

MariaDB [(none)]> grant all privileges on nova_cell0.* to 'nova'@'%' identified by '0000
00';
Query OK, 0 rows affected (0.001 sec)

MariaDB [(none)]> exit
Bye
```

3.创建用户

```shell
[root@controller ~]# source ~/.admin-openrc
[root@controller ~]# openstack user create --domain default --password-prompt nova
User Password:
Repeat User Password:
+---------------------+----------------------------------+
| Field               | Value                            |
+---------------------+----------------------------------+
| domain_id           | default                          |
| enabled             | True                             |
| id                  | 4adefd27201e4eb3a2146a3cc802fa44 |
| name                | nova                             |
| options             | {}                               |
| password_expires_at | None                             |
+---------------------+----------------------------------+
```

4.添加 Nova 用户到 service project 并指定 admin 的 role

```shell
[root@controller ~]# openstack role add --project service --user nova admin
```

5.创建 Nova 服务实体

```shell
[root@controller ~]# openstack service create --name nova --description "OpenStack Compute" compute
+-------------+----------------------------------+
| Field       | Value                            |
+-------------+----------------------------------+
| description | OpenStack Compute                |
| enabled     | True                             |
| id          | 6d0790d16a8f4a16b0803daf44deb8a1 |
| name        | nova                             |
| type        | compute                          |
+-------------+----------------------------------+
```

6.创建 Nova 服务 API 端点

```shell
[root@controller ~]# openstack endpoint create --region RegionOne compute public http://controller:8774/v2.1
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | d109ad0329e143239fbf1b3df7d78434 |
| interface    | public                           |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | 6d0790d16a8f4a16b0803daf44deb8a1 |
| service_name | nova                             |
| service_type | compute                          |
| url          | http://controller:8774/v2.1      |
+--------------+----------------------------------+
[root@controller ~]# openstack endpoint create --region RegionOne compute internal http://controller:8774/v2.1
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | 40358d3d8490445e9db8fb19db6d7f56 |
| interface    | internal                         |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | 6d0790d16a8f4a16b0803daf44deb8a1 |
| service_name | nova                             |
| service_type | compute                          |
| url          | http://controller:8774/v2.1      |
+--------------+----------------------------------+
[root@controller ~]# openstack endpoint create --region RegionOne compute admin http://controller:8774/v2.1
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | 899ba02dc8aa40b484b5e94fc6b542ec |
| interface    | admin                            |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | 6d0790d16a8f4a16b0803daf44deb8a1 |
| service_name | nova                             |
| service_type | compute                          |
| url          | http://controller:8774/v2.1      |
+--------------+----------------------------------+
```

7.编辑 Nova 配置文件

```shell
[root@controller ~]# vim /etc/nova/nova.conf
[DEFAULT]
enabled_apis = osapi_compute,metadata
transport_url = rabbit://openstack:000000@controller:5672/
my_ip = 192.168.100.131
log_dir = /var/log/nova

[api_database]
connection = mysql+pymysql://nova:000000@controller/nova_api

[database]
connection = mysql+pymysql://nova:000000@controller/nova

[api]
auth_strategy = keystone

[keystone_authtoken]
auth_url = http://controller:5000/v3
memcached_servers = controller:11211
auth_type = password
project_domain_name = Default
user_domain_name = Default
project_name = service
username = nova
password = 000000

[vnc]
enabled = true
server_listen = $my_ip
server_proxyclient_address = $my_ip

[glance]
api_servers = http://controller:9292

[oslo_concurrency]
lock_path = /var/lib/nova/tmp

[placement]
region_name = RegionOne
project_domain_name = Default
project_name = service
auth_type = password
user_domain_name = Default
auth_url = http://controller:5000/v3
username = placement
password = 000000
```

![](https://github.com/Xiao254182/notes/blob/master/img/8/16.png)

![](https://github.com/Xiao254182/notes/blob/master/img/8/17.png)

![](https://github.com/Xiao254182/notes/blob/master/img/8/18.png)

![](https://github.com/Xiao254182/notes/blob/master/img/8/19.png)

![](https://github.com/Xiao254182/notes/blob/master/img/8/20.png)

![](https://github.com/Xiao254182/notes/blob/master/img/8/21.png)

![](https://github.com/Xiao254182/notes/blob/master/img/8/22.png)

![](https://github.com/Xiao254182/notes/blob/master/img/8/23.png)

![](https://github.com/Xiao254182/notes/blob/master/img/8/24.png)

8.数据库同步

同步 nova-api 数据库：

```shell
[root@controller ~]# su -s /bin/sh -c "nova-manage api_db sync" nova
```

- 注册cell0数据库：

```shell
[root@controller ~]# su -s /bin/sh -c "nova-manage cell_v2 map_cell0" nova
Cell0 is already setup
```

- 创建cell1 cell：

```shell
[root@controller ~]# su -s /bin/sh -c "nova-manage cell_v2 create_cell --name=cell1 --verbose" nova
--transport-url not provided in the command line, using the value [DEFAULT]/transport_url from the configuration file
--database_connection not provided in the command line, using the value [database]/connection from the configuration file
The specified transport_url and/or database_connection combination already exists for another cell with uuid 0dde93ee-df2e-4da8-acee-3d4cbe729e6b.
```

- 同步nova数据库：

```shell
[root@controller ~]# su -s /bin/sh -c "nova-manage db sync" nova
```

- 验证cell0和cell1注册正确：

```shell
[root@controller ~]# su -s /bin/sh -c "nova-manage cell_v2 list_cells" nova
+-------+--------------------------------------+------------------------------------------+-------------------------------------------------+----------+
|  名称 |                 UUID                 |              Transport URL               |                    数据库连接                   | Disabled |
+-------+--------------------------------------+------------------------------------------+-------------------------------------------------+----------+
| cell0 | 00000000-0000-0000-0000-000000000000 |                  none:/                  | mysql+pymysql://nova:****@controller/nova_cell0 |  False   |
| cell1 | 0dde93ee-df2e-4da8-acee-3d4cbe729e6b | rabbit://openstack:****@controller:5672/ |    mysql+pymysql://nova:****@controller/nova    |  False   |
+-------+--------------------------------------+------------------------------------------+-------------------------------------------------+----------+
```

9.启动服务

```shell
[root@controller ~]# systemctl start openstack-nova-api.service openstack-nova-scheduler.service openstack-nova-conductor.service openstack-nova-novncproxy.service
[root@controller ~]# systemctl enable openstack-nova-api.service openstack-nova-scheduler.service openstack-nova-conductor.service openstack-nova-novncproxy.service
Created symlink /etc/systemd/system/multi-user.target.wants/openstack-nova-api.service → /usr/lib/systemd/system/openstack-nova-api.service.
Created symlink /etc/systemd/system/multi-user.target.wants/openstack-nova-scheduler.service → /usr/lib/systemd/system/openstack-nova-scheduler.service.
Created symlink /etc/systemd/system/multi-user.target.wants/openstack-nova-conductor.service → /usr/lib/systemd/system/openstack-nova-conductor.service.
Created symlink /etc/systemd/system/multi-user.target.wants/openstack-nova-novncproxy.service → /usr/lib/systemd/system/openstack-nova-novncproxy.service.
```

3.4.2 compute 节点

1.安装软件包

```shell
[root@compute ~]# dnf install -y openstack-nova-compute
```

2.编辑 Nova 配置文件

```shell
[root@compute ~]# vim /etc/nova/nova.conf
[DEFAULT]
enabled_apis = osapi_compute,metadata
transport_url = rabbit://openstack:000000@controller:5672/
my_ip = 192.168.100.132
compute_driver = libvirt.LibvirtDriver
instances_path = /var/lib/nova/instances
log_dir = /var/log/nova

[api]
auth_strategy = keystone

[keystone_authtoken]
auth_url = http://controller:5000/v3
memcached_servers = controller:11211
auth_type = password
project_domain_name = Default
user_domain_name = Default
project_name = service
username = nova
password = 000000

[vnc]
enabled = true
server_listen = $my_ip
server_proxyclient_address = $my_ip
novncproxy_base_url = http://controller:6080/vnc_auto.html

[glance]
api_servers = http://controller:9292

[oslo_concurrency]
lock_path = /var/lib/nova/tmp

[placement]
region_name = RegionOne
project_domain_name = Default
project_name = service
auth_type = password
user_domain_name = Default
auth_url = http://controller:5000/v3
username = placement
password = 000000

[libvirt]
virt_type = qemu
```

![](https://github.com/Xiao254182/notes/blob/master/img/8/25.png)

![](https://github.com/Xiao254182/notes/blob/master/img/8/26.png)

![](https://github.com/Xiao254182/notes/blob/master/img/8/27.png)

![](https://github.com/Xiao254182/notes/blob/master/img/8/28.png)

![](https://github.com/Xiao254182/notes/blob/master/img/8/29.png)

![](https://github.com/Xiao254182/notes/blob/master/img/8/30.png)

![](https://github.com/Xiao254182/notes/blob/master/img/8/31.png)

![](https://github.com/Xiao254182/notes/blob/master/img/8/32.png)

3.启动服务

```shell
[root@compute ~]# systemctl start libvirtd.service openstack-nova-compute.service && systemctl enable libvirtd.service openstack-nova-compute.service
Created symlink /etc/systemd/system/multi-user.target.wants/libvirtd.service → /usr/lib/systemd/system/libvirtd.service.
Created symlink /etc/systemd/system/sockets.target.wants/virtlockd.socket → /usr/lib/systemd/system/virtlockd.socket.
Created symlink /etc/systemd/system/sockets.target.wants/virtlogd.socket → /usr/lib/systemd/system/virtlogd.socket.
Created symlink /etc/systemd/system/sockets.target.wants/libvirtd.socket → /usr/lib/systemd/system/libvirtd.socket.
Created symlink /etc/systemd/system/sockets.target.wants/libvirtd-ro.socket → /usr/lib/systemd/system/libvirtd-ro.socket.
Created symlink /etc/systemd/system/multi-user.target.wants/openstack-nova-compute.service → /usr/lib/systemd/system/openstack-nova-compute.service.
```

3.4.3 验证

在 controller 节点验证

1.添加计算节点到 OpenStack 集群

确认nova-compute服务已识别到数据库中：

```shell
[root@controller ~]# source ~/.admin-openrc
[root@controller ~]# openstack compute service list --service nova-compute
+--------------------------------------+--------------+---------+------+---------+-------+----------------------------+
| ID                                   | Binary       | Host    | Zone | Status  | State | Updated At                 |
+--------------------------------------+--------------+---------+------+---------+-------+----------------------------+
| 4c9bbb68-2744-4743-b043-35667c2a88ec | nova-compute | compute | nova | enabled | up    | 2024-07-24T06:45:15.000000 |
+--------------------------------------+--------------+---------+------+---------+-------+----------------------------+
```

发现计算节点，将计算节点添加到cell数据库：

```shell
[root@controller ~]# su -s /bin/sh -c "nova-manage cell_v2 discover_hosts --verbose" nova
Found 2 cell mappings.
Skipping cell0 since it does not contain hosts.
Getting computes from cell 'cell1': 0dde93ee-df2e-4da8-acee-3d4cbe729e6b
Checking host mapping for compute host 'compute': b34c5ac7-19ab-4261-acee-cf44b0c6a07e
Creating host mapping for compute host 'compute': b34c5ac7-19ab-4261-acee-cf44b0c6a07e
Found 1 unmapped computes in cell: 0dde93ee-df2e-4da8-acee-3d4cbe729e6b
```

2.列出服务组件，验证每个流程都成功启动和注册：

```shell
[root@controller ~]# openstack compute service list
+--------------------------------------+----------------+------------+----------+---------+-------+----------------------------+
| ID                                   | Binary         | Host       | Zone     | Status  | State | Updated At                 |
+--------------------------------------+----------------+------------+----------+---------+-------+----------------------------+
| 6604706f-b865-4e36-9936-db5b11d068fa | nova-conductor | controller | internal | enabled | up    | 2024-07-24T06:45:33.000000 |
| 7c3ea14a-1484-4611-8cbd-6345cb098b3f | nova-scheduler | controller | internal | enabled | up    | 2024-07-24T06:45:34.000000 |
| 4c9bbb68-2744-4743-b043-35667c2a88ec | nova-compute   | compute    | nova     | enabled | up    | 2024-07-24T06:45:35.000000 |
+--------------------------------------+----------------+------------+----------+---------+-------+----------------------------+
```

3.列出身份服务中的API端点，验证与身份服务的连接：

```shell
[root@controller ~]# openstack catalog list
+-----------+-----------+-----------------------------------------+
| Name      | Type      | Endpoints                               |
+-----------+-----------+-----------------------------------------+
| nova      | compute   | RegionOne                               |
|           |           |   internal: http://controller:8774/v2.1 |
|           |           | RegionOne                               |
|           |           |   admin: http://controller:8774/v2.1    |
|           |           | RegionOne                               |
|           |           |   public: http://controller:8774/v2.1   |
|           |           |                                         |
| glance    | image     | RegionOne                               |
|           |           |   internal: http://controller:9292      |
|           |           | RegionOne                               |
|           |           |   public: http://controller:9292        |
|           |           | RegionOne                               |
|           |           |   admin: http://controller:9292         |
|           |           |                                         |
| keystone  | identity  | RegionOne                               |
|           |           |   internal: http://controller:5000/v3/  |
|           |           | RegionOne                               |
|           |           |   admin: http://controller:5000/v3/     |
|           |           | RegionOne                               |
|           |           |   public: http://controller:5000/v3/    |
|           |           |                                         |
| placement | placement | RegionOne                               |
|           |           |   public: http://controller:8778        |
|           |           | RegionOne                               |
|           |           |   internal: http://controller:8778      |
|           |           | RegionOne                               |
|           |           |   admin: http://controller:8778         |
|           |           |                                         |
+-----------+-----------+-----------------------------------------+
```

4.列出镜像服务中的镜像，验证与镜像服务的连接：

```shell
[root@controller ~]# openstack image list
+--------------------------------------+--------+--------+
| ID                                   | Name   | Status |
+--------------------------------------+--------+--------+
| c94f006b-ee15-4f1e-8b6f-df7ffb81ee84 | cirros | active |
+--------------------------------------+--------+--------+
```

5.检查cells是否运作成功

```shell
[root@controller ~]# nova-status upgrade check
+---------------------------------------------------------------------+
| Upgrade Check Results                                               |
+---------------------------------------------------------------------+
| Check: Cells v2                                                     |
| Result: Success                                                     |
| Details: None                                                       |
+---------------------------------------------------------------------+
| Check: Placement API                                                |
| Result: Success                                                     |
| Details: None                                                       |
+---------------------------------------------------------------------+
| Check: Cinder API                                                   |
| Result: Success                                                     |
| Details: None                                                       |
+---------------------------------------------------------------------+
| Check: Policy File JSON to YAML Migration                           |
| Result: Success                                                     |
| Details: None                                                       |
+---------------------------------------------------------------------+
| Check: Older than N-1 computes                                      |
| Result: Success                                                     |
| Details: None                                                       |
+---------------------------------------------------------------------+
| Check: hw_machine_type unset                                        |
| Result: Success                                                     |
| Details: None                                                       |
+---------------------------------------------------------------------+
| Check: Service User Token Configuration                             |
| Result: Failure                                                     |
| Details:  Service user token configuration is required for all Nova |
|   services. For more details see the following: https://docs        |
|   .openstack.org/latest/nova/admin/configuration/service-           |
|   user-token.html                                                   |
+---------------------------------------------------------------------+
```

3.5 Neutron 安装

```
Neutron 是 OpenStack 的一个组件，提供了一个中央网络管理系统，用于管理网络资源。可以管理 OpenStack 中的虚拟网络、子网、路由器和防火
墙等资源。
```

在 controller 节点和 compute 节点部署Neutron

3.5.1 controller 节点

1.安装软件包

```shell
[root@controller ~]# dnf install -y openstack-neutron openstack-neutron-linuxbridge iptables-nft ipset openstack-neutron-ml2
```

2.创建 Neutron 数据库并授权

```shell
[root@controller ~]# mysql -uroot -p000000
Welcome to the MariaDB monitor.  Commands end with ; or \g.
Your MariaDB connection id is 118
Server version: 10.11.4-MariaDB MariaDB Server

Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

MariaDB [(none)]> create database neutron;
Query OK, 1 row affected (0.000 sec)

MariaDB [(none)]> grant all privileges on neutron.* to 'neutron'@'localhost' identified
by '000000';
Query OK, 0 rows affected (0.018 sec)

MariaDB [(none)]> grant all privileges on neutron.* to 'neutron'@'%' identified by '0000              00';
Query OK, 0 rows affected (0.001 sec)

MariaDB [(none)]> exit
Bye
```

3.创建用户

```shell
[root@controller ~]# source ~/.admin-openrc
[root@controller ~]# openstack user create --domain default --password-prompt neutron
User Password:
Repeat User Password:
+---------------------+----------------------------------+
| Field               | Value                            |
+---------------------+----------------------------------+
| domain_id           | default                          |
| enabled             | True                             |
| id                  | 52d6796eefef4a99a746637fa6d9624e |
| name                | neutron                          |
| options             | {}                               |
| password_expires_at | None                             |
+---------------------+----------------------------------+
```

4.添加 Neutron 用户到 service project 并指定 admin 的 role

```shell
[root@controller ~]# openstack role add --project service --user neutron admin
```

5.创建 Neutron 服务实体

```shell
[root@controller ~]# openstack service create --name neutron --description "OpenStack Ne              tworking" network
+-------------+----------------------------------+
| Field       | Value                            |
+-------------+----------------------------------+
| description | OpenStack Networking             |
| enabled     | True                             |
| id          | 9089061ca12546cbb48617a33c15251f |
| name        | neutron                          |
| type        | network                          |
+-------------+----------------------------------+
```

6.创建服务 API 端点

```shell
[root@controller ~]# openstack endpoint create --region RegionOne network public http://              controller:9696
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | 2901f43c210a4c928be0df6d7df87625 |
| interface    | public                           |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | 9089061ca12546cbb48617a33c15251f |
| service_name | neutron                          |
| service_type | network                          |
| url          | http://controller:9696           |
+--------------+----------------------------------+
[root@controller ~]# openstack endpoint create --region RegionOne network internal http:              //controller:9696
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | 3ea15cd153a5485c828c65c32e2a3caf |
| interface    | internal                         |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | 9089061ca12546cbb48617a33c15251f |
| service_name | neutron                          |
| service_type | network                          |
| url          | http://controller:9696           |
+--------------+----------------------------------+
[root@controller ~]# openstack endpoint create --region RegionOne network admin http://c              ontroller:9696
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | dd62b1877c774c428e76f95d06fb009f |
| interface    | admin                            |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | 9089061ca12546cbb48617a33c15251f |
| service_name | neutron                          |
| service_type | network                          |
| url          | http://controller:9696           |
+--------------+----------------------------------+
```

7.编辑 Neutron 配置文件

```shell
[root@controller ~]# vim /etc/neutron/neutron.conf
[database]
connection = mysql+pymysql://neutron:000000@controller/neutron

[DEFAULT]
core_plugin = ml2
service_plugins = router
allow_overlapping_ips = true
transport_url = rabbit://openstack:000000@controller
auth_strategy = keystone
notify_nova_on_port_status_changes = true
notify_nova_on_port_data_changes = true

[keystone_authtoken]
www_authenticate_uri = http://controller:5000
auth_url = http://controller:5000
memcached_servers = controller:11211
auth_type = password
project_domain_name = Default
user_domain_name = Default
project_name = service
username = neutron
password = 000000

[nova]
auth_url = http://controller:5000
auth_type = password
project_domain_name = Default
user_domain_name = Default
region_name = RegionOne
project_name = service
username = nova
password = 000000

[oslo_concurrency]
lock_path = /var/lib/neutron/tmp

[experimental]
linuxbridge = true
```

![](https://github.com/Xiao254182/notes/blob/master/img/8/33.png)

![](https://github.com/Xiao254182/notes/blob/master/img/8/34.png)

![](https://github.com/Xiao254182/notes/blob/master/img/8/35.png)

![](https://github.com/Xiao254182/notes/blob/master/img/8/36.png)

8.配置 ML2

```shell
[root@controller ~]# vim /etc/neutron/plugins/ml2/ml2_conf.ini
[ml2]
type_drivers = flat,vlan,vxlan
tenant_network_types = vxlan
mechanism_drivers = linuxbridge,l2population
extension_drivers = port_security

[ml2_type_flat]
flat_networks = provider

[ml2_type_vxlan]
vni_ranges = 1:1000

[securitygroup]
enable_ipset = true
```

![](https://github.com/Xiao254182/notes/blob/master/img/8/37.png)

9.配置 `/etc/neutron/plugins/ml2/linuxbridge_agent.ini` 文件

```shell
[root@controller ~]# vim /etc/neutron/plugins/ml2/linuxbridge_agent.ini
[linux_bridge]
physical_interface_mappings = provider:ens32  #此处需要写当前环境上物理网络接口的名称

[vxlan]
enable_vxlan = true
local_ip = 192.168.100.131
l2_population = true

[securitygroup]
enable_security_group = true
firewall_driver = neutron.agent.linux.iptables_firewall.IptablesFirewallDriver
```

![](https://github.com/Xiao254182/notes/blob/master/img/8/38.png)

10.配置 Layer-3 代理

```shell
[root@controller ~]# vim /etc/neutron/l3_agent.ini
[DEFAULT]
interface_driver = linuxbridge
```

![](https://github.com/Xiao254182/notes/blob/master/img/8/39.png)

11.配置 DHCP 代理

```shell
[root@controller ~]# vim /etc/neutron/dhcp_agent.ini
[DEFAULT]
interface_driver = linuxbridge
dhcp_driver = neutron.agent.linux.dhcp.Dnsmasq
enable_isolated_metadata = true
```

![](https://github.com/Xiao254182/notes/blob/master/img/8/40.png)

12.配置 metadata 代理

```shell
[root@controller ~]# vim /etc/neutron/metadata_agent.ini
[DEFAULT]
nova_metadata_host = controller
metadata_proxy_shared_secret = 7d8f008607a14b63aaf2 #此处为生成的随机数，可使用"openssl rand -hex 10"命令生成
```

![](https://github.com/Xiao254182/notes/blob/master/img/8/41.png)

13.配置 Nova 服务

```shell
[root@controller ~]# vim /etc/nova/nova.conf
[neutron]
auth_url = http://controller:5000
auth_type = password
project_domain_name = Default
user_domain_name = Default
region_name = RegionOne
project_name = service
username = neutron
password = 000000
service_metadata_proxy = true
metadata_proxy_shared_secret = 41010849029170bef8df   #此处为生成的随机数，可使用"openssl rand -hex 10"命令生成
```

![](https://github.com/Xiao254182/notes/blob/master/img/8/42.png) 

14.创建 `/etc/neutron/plugin.ini` 的符号链接

```shell
[root@controller ~]# ln -s /etc/neutron/plugins/ml2/ml2_conf.ini /etc/neutron/plugin.ini
```

15.同步数据库

```shell
[root@controller ~]# su -s /bin/sh -c "neutron-db-manage --config-file /etc/neutron/neut              ron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini upgrade head" neutron
INFO  [alembic.runtime.migration] Context impl MySQLImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
  正在对 neutron 运行 upgrade...
INFO  [alembic.runtime.migration] Context impl MySQLImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
INFO  [alembic.runtime.migration] Running upgrade  -> kilo
INFO  [alembic.runtime.migration] Running upgrade kilo -> 354db87e3225
INFO  [alembic.runtime.migration] Running upgrade 354db87e3225 -> 599c6a226151
INFO  [alembic.runtime.migration] Running upgrade 599c6a226151 -> 52c5312f6baf
INFO  [alembic.runtime.migration] Running upgrade 52c5312f6baf -> 313373c0ffee
INFO  [alembic.runtime.migration] Running upgrade 313373c0ffee -> 8675309a5c4f
INFO  [alembic.runtime.migration] Running upgrade 8675309a5c4f -> 45f955889773
INFO  [alembic.runtime.migration] Running upgrade 45f955889773 -> 26c371498592
INFO  [alembic.runtime.migration] Running upgrade 26c371498592 -> 1c844d1677f7
INFO  [alembic.runtime.migration] Running upgrade 1c844d1677f7 -> 1b4c6e320f79
INFO  [alembic.runtime.migration] Running upgrade 1b4c6e320f79 -> 48153cb5f051
INFO  [alembic.runtime.migration] Running upgrade 48153cb5f051 -> 9859ac9c136
INFO  [alembic.runtime.migration] Running upgrade 9859ac9c136 -> 34af2b5c5a59
INFO  [alembic.runtime.migration] Running upgrade 34af2b5c5a59 -> 59cb5b6cf4d
INFO  [alembic.runtime.migration] Running upgrade 59cb5b6cf4d -> 13cfb89f881a
INFO  [alembic.runtime.migration] Running upgrade 13cfb89f881a -> 32e5974ada25
INFO  [alembic.runtime.migration] Running upgrade 32e5974ada25 -> ec7fcfbf72ee
INFO  [alembic.runtime.migration] Running upgrade ec7fcfbf72ee -> dce3ec7a25c9
INFO  [alembic.runtime.migration] Running upgrade dce3ec7a25c9 -> c3a73f615e4
INFO  [alembic.runtime.migration] Running upgrade c3a73f615e4 -> 659bf3d90664
INFO  [alembic.runtime.migration] Running upgrade 659bf3d90664 -> 1df244e556f5
INFO  [alembic.runtime.migration] Running upgrade 1df244e556f5 -> 19f26505c74f
INFO  [alembic.runtime.migration] Running upgrade 19f26505c74f -> 15be73214821
INFO  [alembic.runtime.migration] Running upgrade 15be73214821 -> b4caf27aae4
INFO  [alembic.runtime.migration] Running upgrade b4caf27aae4 -> 15e43b934f81
INFO  [alembic.runtime.migration] Running upgrade 15e43b934f81 -> 31ed664953e6
INFO  [alembic.runtime.migration] Running upgrade 31ed664953e6 -> 2f9e956e7532
INFO  [alembic.runtime.migration] Running upgrade 2f9e956e7532 -> 3894bccad37f
INFO  [alembic.runtime.migration] Running upgrade 3894bccad37f -> 0e66c5227a8a
INFO  [alembic.runtime.migration] Running upgrade 0e66c5227a8a -> 45f8dd33480b
INFO  [alembic.runtime.migration] Running upgrade 45f8dd33480b -> 5abc0278ca73
INFO  [alembic.runtime.migration] Running upgrade 5abc0278ca73 -> d3435b514502
INFO  [alembic.runtime.migration] Running upgrade d3435b514502 -> 30107ab6a3ee
INFO  [alembic.runtime.migration] Running upgrade 30107ab6a3ee -> c415aab1c048
INFO  [alembic.runtime.migration] Running upgrade c415aab1c048 -> a963b38d82f4
INFO  [alembic.runtime.migration] Running upgrade kilo -> 30018084ec99
INFO  [alembic.runtime.migration] Running upgrade 30018084ec99 -> 4ffceebfada
INFO  [alembic.runtime.migration] Running upgrade 4ffceebfada -> 5498d17be016
INFO  [alembic.runtime.migration] Running upgrade 5498d17be016 -> 2a16083502f3
INFO  [alembic.runtime.migration] Running upgrade 2a16083502f3 -> 2e5352a0ad4d
INFO  [alembic.runtime.migration] Running upgrade 2e5352a0ad4d -> 11926bcfe72d
INFO  [alembic.runtime.migration] Running upgrade 11926bcfe72d -> 4af11ca47297
INFO  [alembic.runtime.migration] Running upgrade 4af11ca47297 -> 1b294093239c
INFO  [alembic.runtime.migration] Running upgrade 1b294093239c -> 8a6d8bdae39
INFO  [alembic.runtime.migration] Running upgrade 8a6d8bdae39 -> 2b4c2465d44b
INFO  [alembic.runtime.migration] Running upgrade 2b4c2465d44b -> e3278ee65050
INFO  [alembic.runtime.migration] Running upgrade e3278ee65050 -> c6c112992c9
INFO  [alembic.runtime.migration] Running upgrade c6c112992c9 -> 5ffceebfada
INFO  [alembic.runtime.migration] Running upgrade 5ffceebfada -> 4ffceebfcdc
INFO  [alembic.runtime.migration] Running upgrade 4ffceebfcdc -> 7bbb25278f53
INFO  [alembic.runtime.migration] Running upgrade 7bbb25278f53 -> 89ab9a816d70
INFO  [alembic.runtime.migration] Running upgrade 89ab9a816d70 -> c879c5e1ee90
INFO  [alembic.runtime.migration] Running upgrade c879c5e1ee90 -> 8fd3918ef6f4
INFO  [alembic.runtime.migration] Running upgrade 8fd3918ef6f4 -> 4bcd4df1f426
INFO  [alembic.runtime.migration] Running upgrade 4bcd4df1f426 -> b67e765a3524
INFO  [alembic.runtime.migration] Running upgrade a963b38d82f4 -> 3d0e74aa7d37
INFO  [alembic.runtime.migration] Running upgrade 3d0e74aa7d37 -> 030a959ceafa
INFO  [alembic.runtime.migration] Running upgrade 030a959ceafa -> a5648cfeeadf
INFO  [alembic.runtime.migration] Running upgrade a5648cfeeadf -> 0f5bef0f87d4
INFO  [alembic.runtime.migration] Running upgrade 0f5bef0f87d4 -> 67daae611b6e
INFO  [alembic.runtime.migration] Running upgrade b67e765a3524 -> a84ccf28f06a
INFO  [alembic.runtime.migration] Running upgrade a84ccf28f06a -> 7d9d8eeec6ad
INFO  [alembic.runtime.migration] Running upgrade 67daae611b6e -> 6b461a21bcfc
INFO  [alembic.runtime.migration] Running upgrade 6b461a21bcfc -> 5cd92597d11d
INFO  [alembic.runtime.migration] Running upgrade 5cd92597d11d -> 929c968efe70
INFO  [alembic.runtime.migration] Running upgrade 929c968efe70 -> a9c43481023c
INFO  [alembic.runtime.migration] Running upgrade a9c43481023c -> 804a3c76314c
INFO  [alembic.runtime.migration] Running upgrade 804a3c76314c -> 2b42d90729da
INFO  [alembic.runtime.migration] Running upgrade 2b42d90729da -> 62c781cb6192
INFO  [alembic.runtime.migration] Running upgrade 62c781cb6192 -> c8c222d42aa9
INFO  [alembic.runtime.migration] Running upgrade c8c222d42aa9 -> 349b6fd605a6
INFO  [alembic.runtime.migration] Running upgrade 349b6fd605a6 -> 7d32f979895f
INFO  [alembic.runtime.migration] Running upgrade 7d32f979895f -> 594422d373ee
INFO  [alembic.runtime.migration] Running upgrade 594422d373ee -> 61663558142c
INFO  [alembic.runtime.migration] Running upgrade 61663558142c -> 867d39095bf4, port for              warding
INFO  [alembic.runtime.migration] Running upgrade 867d39095bf4 -> d72db3e25539, modify u              niq port forwarding
INFO  [alembic.runtime.migration] Running upgrade d72db3e25539 -> cada2437bf41
INFO  [alembic.runtime.migration] Running upgrade cada2437bf41 -> 195176fb410d, router g              ateway IP QoS
INFO  [alembic.runtime.migration] Running upgrade 195176fb410d -> fb0167bd9639
INFO  [alembic.runtime.migration] Running upgrade fb0167bd9639 -> 0ff9e3881597
INFO  [alembic.runtime.migration] Running upgrade 0ff9e3881597 -> 9bfad3f1e780
INFO  [alembic.runtime.migration] Running upgrade 9bfad3f1e780 -> 63fd95af7dcd
INFO  [alembic.runtime.migration] Running upgrade 63fd95af7dcd -> c613d0b82681
INFO  [alembic.runtime.migration] Running upgrade c613d0b82681 -> c3e9d13c4367
INFO  [alembic.runtime.migration] Running upgrade c3e9d13c4367 -> 86274d77933e
INFO  [alembic.runtime.migration] Running upgrade 86274d77933e -> f4b9654dd40c
INFO  [alembic.runtime.migration] Running upgrade f4b9654dd40c -> a010322604bc
INFO  [alembic.runtime.migration] Running upgrade a010322604bc -> 263d454a9655
INFO  [alembic.runtime.migration] Running upgrade 263d454a9655 -> Ibac91d24da2
INFO  [alembic.runtime.migration] Running upgrade Ibac91d24da2 -> 2217c4222de6
INFO  [alembic.runtime.migration] Running upgrade 2217c4222de6 -> 18a7e90ae768
INFO  [alembic.runtime.migration] Running upgrade 18a7e90ae768 -> e4e236b0e1ff
INFO  [alembic.runtime.migration] Running upgrade e4e236b0e1ff -> e88badaa9591
INFO  [alembic.runtime.migration] Running upgrade e88badaa9591 -> d8bdf05313f4
INFO  [alembic.runtime.migration] Running upgrade d8bdf05313f4 -> dfe425060830
INFO  [alembic.runtime.migration] Running upgrade dfe425060830 -> fd6107509ccd
INFO  [alembic.runtime.migration] Running upgrade fd6107509ccd -> 1ea5dab0897a
INFO  [alembic.runtime.migration] Running upgrade 1ea5dab0897a -> 49d8622c5221
INFO  [alembic.runtime.migration] Running upgrade 49d8622c5221 -> I38991de2b4
INFO  [alembic.runtime.migration] Running upgrade I38991de2b4 -> 532aa95457e2
INFO  [alembic.runtime.migration] Running upgrade 532aa95457e2 -> f010820fc498
INFO  [alembic.runtime.migration] Running upgrade f010820fc498 -> a964d94b4677
INFO  [alembic.runtime.migration] Running upgrade a964d94b4677 -> 26d1e9f5c766
INFO  [alembic.runtime.migration] Running upgrade 26d1e9f5c766 -> 1e0744e4ffea
INFO  [alembic.runtime.migration] Running upgrade 1e0744e4ffea -> 6135a7bd4425
INFO  [alembic.runtime.migration] Running upgrade 6135a7bd4425 -> 8df53b0d2c0e
INFO  [alembic.runtime.migration] Running upgrade 8df53b0d2c0e -> 1bb3393de75d, add qos               policy rule Packet Rate Limit
INFO  [alembic.runtime.migration] Running upgrade 1bb3393de75d -> c181bb1d89e4
INFO  [alembic.runtime.migration] Running upgrade c181bb1d89e4 -> ba859d649675
INFO  [alembic.runtime.migration] Running upgrade ba859d649675 -> e981acd076d3
INFO  [alembic.runtime.migration] Running upgrade e981acd076d3 -> 76df7844a8c6, add Loca              l IP tables
INFO  [alembic.runtime.migration] Running upgrade 76df7844a8c6 -> 1ffef8d6f371, migrate               RBAC registers from "target_tenant" to "target_project"
INFO  [alembic.runtime.migration] Running upgrade 1ffef8d6f371 -> 8160f7a9cebb, drop por              tbindingports table
INFO  [alembic.runtime.migration] Running upgrade 8160f7a9cebb -> cd9ef14ccf87
INFO  [alembic.runtime.migration] Running upgrade cd9ef14ccf87 -> 34cf8b009713
INFO  [alembic.runtime.migration] Running upgrade 34cf8b009713 -> I43e0b669096
INFO  [alembic.runtime.migration] Running upgrade I43e0b669096 -> 4e6e655746f6
INFO  [alembic.runtime.migration] Running upgrade 4e6e655746f6 -> 659cbedf30a1
INFO  [alembic.runtime.migration] Running upgrade 659cbedf30a1 -> 21ff98fabab1
INFO  [alembic.runtime.migration] Running upgrade 21ff98fabab1 -> 5881373af7f5
INFO  [alembic.runtime.migration] Running upgrade 7d9d8eeec6ad -> a8b517cff8ab
INFO  [alembic.runtime.migration] Running upgrade a8b517cff8ab -> 3b935b28e7a0
INFO  [alembic.runtime.migration] Running upgrade 3b935b28e7a0 -> b12a3ef66e62
INFO  [alembic.runtime.migration] Running upgrade b12a3ef66e62 -> 97c25b0d2353
INFO  [alembic.runtime.migration] Running upgrade 97c25b0d2353 -> 2e0d7a8a1586
INFO  [alembic.runtime.migration] Running upgrade 2e0d7a8a1586 -> 5c85685d616d
  确定
```

16.重新启动 Nova api 服务

```shell
[root@controller ~]# systemctl restart openstack-nova-api.service
```

17.启动网络服务

```shell
[root@controller ~]# systemctl start neutron-server.service neutron-linuxbridge-agent.service neutron-dhcp-agent.service neutron-metadata-agent.service neutron-l3-agent.service && systemctl enable neutron-server.service neutron-linuxbridge-agent.service neutron-dhcp-agent.service neutron-metadata-agent.service neutron-l3-agent.service
Created symlink /etc/systemd/system/multi-user.target.wants/neutron-server.service → /us              r/lib/systemd/system/neutron-server.service.
Created symlink /etc/systemd/system/multi-user.target.wants/neutron-linuxbridge-agent.se              rvice → /usr/lib/systemd/system/neutron-linuxbridge-agent.service.
Created symlink /etc/systemd/system/multi-user.target.wants/neutron-dhcp-agent.service →               /usr/lib/systemd/system/neutron-dhcp-agent.service.
Created symlink /etc/systemd/system/multi-user.target.wants/neutron-metadata-agent.servi              ce → /usr/lib/systemd/system/neutron-metadata-agent.service.
Created symlink /etc/systemd/system/multi-user.target.wants/neutron-l3-agent.service → /              usr/lib/systemd/system/neutron-l3-agent.service.
```

3.5.2 compute 节点

1.安装软件包

```shell
[root@compute ~]# dnf install -y openstack-neutron-linuxbridge ebtables ipset
```

2.编辑 Neutron 配置文件

```shell
[root@compute ~]# vim /etc/neutron/neutron.conf
[DEFAULT]
transport_url = rabbit://openstack:000000@controller
auth_strategy = keystone

[keystone_authtoken]
www_authenticate_uri = http://controller:5000
auth_url = http://controller:5000
memcached_servers = controller:11211
auth_type = password
project_domain_name = Default
user_domain_name = Default
project_name = service
username = neutron
password = 000000

[oslo_concurrency]
lock_path = /var/lib/neutron/tmp
```

![](https://github.com/Xiao254182/notes/blob/master/img/8/43.png)

![](https://github.com/Xiao254182/notes/blob/master/img/8/44.png)

![](https://github.com/Xiao254182/notes/blob/master/img/8/45.png)

3.编辑 `/etc/neutron/plugins/ml2/linuxbridge_agent.ini` 文件

```shell
[root@compute ~]# vim /etc/neutron/plugins/ml2/linuxbridge_agent.ini
[linux_bridge]
physical_interface_mappings = provider:ens32   #此处需要写当前环境上物理网络接口的名称

[vxlan]
enable_vxlan = true
local_ip = 192.168.100.132
l2_population = true

[securitygroup]
enable_security_group = true
firewall_driver = neutron.agent.linux.iptables_firewall.IptablesFirewallDriver
```

![](https://github.com/Xiao254182/notes/blob/master/img/8/46.png)

4.配置 Nova 服务

```shell
[root@compute ~]# vim /etc/nova/nova.conf
[neutron]
auth_url = http://controller:5000
auth_type = password
project_domain_name = default
user_domain_name = default
region_name = RegionOne
project_name = service
username = neutron
password = 000000
```

![](https://github.com/Xiao254182/notes/blob/master/img/8/47.png)

5.重启 nova-compute 服务

```shell
[root@compute ~]# systemctl restart openstack-nova-compute.service
```

6.启动 Neutron linuxbridge agent 服务

```shell
[root@compute ~]# systemctl start neutron-linuxbridge-agent && systemctl enable neutron-linuxbridge-agent
Created symlink /etc/systemd/system/multi-user.target.wants/neutron-linuxbridge-agent.service → /us                r/lib/systemd/system/neutron-linuxbridge-agent.service.
```

3.5.3 验证

验证在 controller 节点执行，通过如下命令确认 neutron 代理启动成功即可

```shell
[root@controller ~]# openstack network agent list
+--------------------------------------+--------------------+------------+--------------              -----+-------+-------+---------------------------+
| ID                                   | Agent Type         | Host       | Availability               Zone | Alive | State | Binary                    |
+--------------------------------------+--------------------+------------+--------------              -----+-------+-------+---------------------------+
| 09b38901-39d2-4316-a655-23a4fa71cbe0 | Metadata agent     | controller | None                            | :-)   | UP    | neutron-metadata-agent    |
| 2a60cde0-9370-45f3-8035-186f80a81550 | Linux bridge agent | controller | None                            | :-)   | UP    | neutron-linuxbridge-agent |
| 61341a3d-3e4d-4a81-a353-59804d0bf6b7 | L3 agent           | controller | nova                            | :-)   | UP    | neutron-l3-agent          |
| a22b2062-76e7-4519-887a-e23ce82d0d12 | DHCP agent         | controller | nova                            | :-)   | UP    | neutron-dhcp-agent        |
| ed1166e6-874c-4642-a886-98d5cd729a79 | Linux bridge agent | compute    | None                            | :-)   | UP    | neutron-linuxbridge-agent |
+--------------------------------------+--------------------+------------+--------------              -----+-------+-------+---------------------------+
```

3.6 安装Cinder

```
Cinder 提供了一个中央块存储管理系统，用于管理 OpenStack 中的块存储卷和快照等资源。
```

在controller节点和storage节点部署Cinder

3.6.1 controller节点

1.安装软件包

```shell
[root@controller ~]# dnf install openstack-cinder-api openstack-cinder-scheduler -y
```

2.创建 Cinder 数据库并授权

```shell
[root@controller ~]# mysql -uroot -p000000
Welcome to the MariaDB monitor.  Commands end with ; or \g.
Your MariaDB connection id is 172
Server version: 10.11.4-MariaDB MariaDB Server

Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

MariaDB [(none)]> create database cinder;
Query OK, 1 row affected (0.001 sec)

MariaDB [(none)]> grant all privileges on cinder.* to 'cinder'@'localhost' identified by '000000';
Query OK, 0 rows affected (0.004 sec)

MariaDB [(none)]> grant all privileges on cinder.* to 'cinder'@'%' identified by '000000';
Query OK, 0 rows affected (0.001 sec)

MariaDB [(none)]> exit
Bye
```

3.创建用户

```shell
[root@controller ~]# source ~/.admin-openrc
[root@controller ~]# openstack user create --domain default --password-prompt cinder
User Password:
Repeat User Password:
+---------------------+----------------------------------+
| Field               | Value                            |
+---------------------+----------------------------------+
| domain_id           | default                          |
| enabled             | True                             |
| id                  | 10d8e8e0c90c4d958373309e3062e238 |
| name                | cinder                           |
| options             | {}                               |
| password_expires_at | None                             |
+---------------------+----------------------------------+
```

4.添加 Cinder 用户到 service project 并指定 admin 的 role

```shell
[root@controller ~]# openstack role add --project service --user cinder admin
```

5.创建 Cinder 服务实体

```shell
[root@controller ~]# openstack service create --name cinderv3 --description "OpenStack Block Storage" volumev3
+-------------+----------------------------------+
| Field       | Value                            |
+-------------+----------------------------------+
| description | OpenStack Block Storage          |
| enabled     | True                             |
| id          | ae8d7c58427a46b7bed74692c81c3c70 |
| name        | cinderv3                         |
| type        | volumev3                         |
+-------------+----------------------------------+
```

6.创建服务 API 端点

```shell
[root@controller ~]# openstack endpoint create --region RegionOne volumev3 public http://controller:8776/v3/%\(project_id\)s
+--------------+------------------------------------------+
| Field        | Value                                    |
+--------------+------------------------------------------+
| enabled      | True                                     |
| id           | 52af5bb3076c4cc4a74ed21897d733d9         |
| interface    | public                                   |
| region       | RegionOne                                |
| region_id    | RegionOne                                |
| service_id   | ae8d7c58427a46b7bed74692c81c3c70         |
| service_name | cinderv3                                 |
| service_type | volumev3                                 |
| url          | http://controller:8776/v3/%(project_id)s |
+--------------+------------------------------------------+
[root@controller ~]# openstack endpoint create --region RegionOne volumev3 internal http://controller:8776/v3/%\(project_id\)s
+--------------+------------------------------------------+
| Field        | Value                                    |
+--------------+------------------------------------------+
| enabled      | True                                     |
| id           | e15d37faed9747bab64f265f6fcc092b         |
| interface    | internal                                 |
| region       | RegionOne                                |
| region_id    | RegionOne                                |
| service_id   | ae8d7c58427a46b7bed74692c81c3c70         |
| service_name | cinderv3                                 |
| service_type | volumev3                                 |
| url          | http://controller:8776/v3/%(project_id)s |
+--------------+------------------------------------------+
[root@controller ~]# openstack endpoint create --region RegionOne volumev3 admin http://controller:8776/v3/%\(project_id\)s
+--------------+------------------------------------------+
| Field        | Value                                    |
+--------------+------------------------------------------+
| enabled      | True                                     |
| id           | 037a696d0ec742f3ab282b508961f5b8         |
| interface    | admin                                    |
| region       | RegionOne                                |
| region_id    | RegionOne                                |
| service_id   | ae8d7c58427a46b7bed74692c81c3c70         |
| service_name | cinderv3                                 |
| service_type | volumev3                                 |
| url          | http://controller:8776/v3/%(project_id)s |
+--------------+------------------------------------------+
```

7.编辑 Cinder 配置文件

```shell
[root@controller ~]# vim /etc/cinder/cinder.conf
[DEFAULT]
transport_url = rabbit://openstack:000000@controller
auth_strategy = keystone
my_ip = 192.168.100.131

[database]
connection = mysql+pymysql://cinder:000000@controller/cinder

[keystone_authtoken]
www_authenticate_uri = http://controller:5000
auth_url = http://controller:5000
memcached_servers = controller:11211
auth_type = password
project_domain_name = Default
user_domain_name = Default
project_name = service
username = cinder
password = 000000

[oslo_concurrency]
lock_path = /var/lib/cinder/tmp
```

![](https://github.com/Xiao254182/notes/blob/master/img/8/48.png)

![](https://github.com/Xiao254182/notes/blob/master/img/8/49.png)

![](https://github.com/Xiao254182/notes/blob/master/img/8/50.png)

![](https://github.com/Xiao254182/notes/blob/master/img/8/51.png)

8.数据库同步

```shell
[root@controller ~]# su -s /bin/sh -c "cinder-manage db sync" cinder
2024-07-24 16:05:05.507 209736 INFO cinder.db.migration [-] Applying migration(s)
2024-07-24 16:05:05.508 209736 INFO alembic.runtime.migration [-] Context impl MySQLImpl.
2024-07-24 16:05:05.508 209736 INFO alembic.runtime.migration [-] Will assume non-transactional DDL.
2024-07-24 16:05:05.516 209736 INFO alembic.runtime.migration [-] Running upgrade  -> 921e1a36b076, Initial migration.
2024-07-24 16:05:05.901 209736 INFO alembic.runtime.migration [-] Running upgrade 921e1a36b076 -> c92a3e68beed, Make shared_targets nullable
2024-07-24 16:05:05.914 209736 INFO cinder.db.migration [-] Migration(s) applied
```

9.配置 Nova 服务

```shell
[root@controller ~]# vim /etc/nova/nova.conf
[cinder]
os_region_name = RegionOne
```

![](https://github.com/Xiao254182/notes/blob/master/img/8/52.png)

10.重启 nova-api 服务，并启动 Cinder 相关服务

```shell
[root@controller ~]# systemctl restart openstack-nova-api && systemctl start openstack-cinder-api openstack-cinder-scheduler
```

3.6.2 storage节点

Storage 节点要提前准备至少一块硬盘，作为 Cinder 的存储后端，本文设备名称为 `/dev/sdb`

Cinder支持很多类型的后端存储，本次部署使用最简单的lvm

1.安装软件包

```shell
[root@storage ~]# dnf install -y lvm2 device-mapper-persistent-data scsi-target-utils rpcbind nfs-utils openstack-cinder-volume openstack-cinder-backup
```

2.配置lvm卷组

```shell
[root@storage ~]# lsblk -l
NAME             MAJ:MIN RM  SIZE RO TYPE MOUNTPOINTS
sda                8:0    0   50G  0 disk
sda1               8:1    0    1M  0 part
sda2               8:2    0    1G  0 part /boot
sda3               8:3    0   49G  0 part
sdb                8:16   0   50G  0 disk
sdc                8:32   0   50G  0 disk
sdd                8:48   0   50G  0 disk
sr0               11:0    1 1024M  0 rom
opencloudos-root 251:0    0   49G  0 lvm  /
[root@storage ~]# pvcreate /dev/sdb
  Physical volume "/dev/sdb" successfully created.
[root@storage ~]# vgcreate cinder-volumes /dev/sdb
  Volume group "cinder-volumes" successfully created
```

3.编辑 Cinder 配置文件

```shell
[root@storage ~]# vim /etc/cinder/cinder.conf
[DEFAULT]
transport_url = rabbit://openstack:000000@controller
auth_strategy = keystone
my_ip = 192.168.100.133
enabled_backends = lvm
glance_api_servers = http://controller:9292

[keystone_authtoken]
www_authenticate_uri = http://controller:5000
auth_url = http://controller:5000
memcached_servers = controller:11211
auth_type = password
project_domain_name = default
user_domain_name = default
project_name = service
username = cinder
password = 000000

[database]
connection = mysql+pymysql://cinder:000000@controller/cinder

[lvm]
volume_driver = cinder.volume.drivers.lvm.LVMVolumeDriver
volume_group = cinder-volumes
target_protocol = iscsi
target_helper = lioadm

[oslo_concurrency]
lock_path = /var/lib/cinder/tmp
```

![](https://github.com/Xiao254182/notes/blob/master/img/8/53.png)

![](https://github.com/Xiao254182/notes/blob/master/img/8/54.png)

![](https://github.com/Xiao254182/notes/blob/master/img/8/55.png)

![](https://github.com/Xiao254182/notes/blob/master/img/8/56.png)

4.启动服务

```shell
[root@storage ~]# systemctl start openstack-cinder-volume target
```

3.6.3 验证

验证在 controller 节点，执行如下命令确认 Cinder 是否正常部署

```shell
[root@controller ~]# source ~/.admin-openrc
[root@controller ~]# openstack volume service list
+------------------+-------------+------+---------+-------+----------------------------+
| Binary           | Host        | Zone | Status  | State | Updated At                 |
+------------------+-------------+------+---------+-------+----------------------------+
| cinder-scheduler | controller  | nova | enabled | up    | 2024-07-24T08:11:38.000000 |
| cinder-volume    | storage@lvm | nova | enabled | up    | 2024-07-24T08:11:43.000000 |
+------------------+-------------+------+---------+-------+----------------------------+
```

3.7 部署Horizon

```
Horizon 提供了一个易于使用的Web界面，用于管理 OpenStack 中的计算、存储、网络和安全等资源。
```

在controller节点部署Horizon

1.安装软件包

```shell
[root@controller ~]# dnf install -y openstack-dashboard
```

2.编辑 Horizon 配置文件

```shell
[root@controller ~]# vim /etc/openstack-dashboard/local_settings
OPENSTACK_HOST = "controller"
ALLOWED_HOSTS = ['*', ]
OPENSTACK_KEYSTONE_URL =  "http://controller:5000/v3"
SESSION_ENGINE = 'django.contrib.sessions.backends.cache'
CACHES = {
'default': {
      'BACKEND': 'django.core.cache.backends.memcached.MemcachedCache',
      'LOCATION': 'controller:11211',
      }
}
OPENSTACK_KEYSTONE_MULTIDOMAIN_SUPPORT = True
OPENSTACK_KEYSTONE_DEFAULT_DOMAIN = "Default"
OPENSTACK_KEYSTONE_DEFAULT_ROLE = "member"
WEBROOT = '/dashboard'
POLICY_FILES_PATH = "/etc/openstack-dashboard"

OPENSTACK_API_VERSIONS = {
      "identity": 3,
      "image": 2,
      "volume": 3,
}
```

![](https://github.com/Xiao254182/notes/blob/master/img/8/57.png)

![](https://github.com/Xiao254182/notes/blob/master/img/8/59.png)

![](https://github.com/Xiao254182/notes/blob/master/img/8/60.png)

3.重启服务

```shell
[root@controller ~]# systemctl restart httpd
```

4.验证

打开浏览器，输入 `http://192.168.100.131/dashboard`，打开 Horizon 登录页面。

![](https://github.com/Xiao254182/notes/blob/master/img/8/58.png)

用户名：admin 密码：000000 域：default

3.8 安装Kolla

```
Kolla 提供了一组工具和脚本可以自动化地构建和部署 OpenStack 容器镜像，简化了OpenStack的部署和管理
```

在controller节点安装Kolla

部署 Kolla 通过 dnf 安装如下 rpm 包即可

```shell
[root@controller ~]# dnf install -y openstack-kolla openstack-kolla-ansible
```

3.9 部署Trove

```
Trove 提供数据库即服务（DBaaS）用于管理和查询数据库资源，帮助用户更轻松地部署和管理数据库，提高数据库的可用性和可扩展性。
```

在controller节点部署Trove

1.安装软件包

```shell
[root@controller ~]# dnf install -y openstack-trove python-troveclient
```

2.创建 Trove 数据库并授权

```shell
[root@controller ~]# mysql -uroot -p000000
Welcome to the MariaDB monitor.  Commands end with ; or \g.
Your MariaDB connection id is 240
Server version: 10.11.4-MariaDB MariaDB Server

Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

MariaDB [(none)]> create database trove character set utf8;
Query OK, 1 row affected (0.001 sec)

MariaDB [(none)]> grant all privileges on trove.* to 'trove'@'localhost' identified by '000000';
Query OK, 0 rows affected (0.001 sec)

MariaDB [(none)]> grant all privileges on trove.* to 'trove'@'%' identified by '000000';
Query OK, 0 rows affected (0.019 sec)

MariaDB [(none)]> exit
Bye
```

3.创建用户

```shell
[root@controller ~]# source ~/.admin-openrc
[root@controller ~]# openstack user create --domain default --password-prompt trove
User Password:
Repeat User Password:
+---------------------+----------------------------------+
| Field               | Value                            |
+---------------------+----------------------------------+
| domain_id           | default                          |
| enabled             | True                             |
| id                  | cfc29b42d0134a1f94aa053003c9f4b3 |
| name                | trove                            |
| options             | {}                               |
| password_expires_at | None                             |
+---------------------+----------------------------------+
```

4.添加 Trove 用户到 service project 并指定 admin 的 role

```shell
[root@controller ~]# openstack role add --project service --user trove admin
```

5.创建 Trove 服务实体

```shell
[root@controller ~]# openstack service create --name trove --description "Database service" database
+-------------+----------------------------------+
| Field       | Value                            |
+-------------+----------------------------------+
| description | Database service                 |
| enabled     | True                             |
| id          | 439f86cc8879428f9a25fc12d90d3982 |
| name        | trove                            |
| type        | database                         |
+-------------+----------------------------------+
```

6.创建服务 API 端点

```shell
[root@controller ~]# openstack endpoint create --region RegionOne database public http://controller:8779/v1.0/%\(tenant_id\)s
+--------------+-------------------------------------------+
| Field        | Value                                     |
+--------------+-------------------------------------------+
| enabled      | True                                      |
| id           | 5d3608693be24b718f28af08e5b36af5          |
| interface    | public                                    |
| region       | RegionOne                                 |
| region_id    | RegionOne                                 |
| service_id   | 439f86cc8879428f9a25fc12d90d3982          |
| service_name | trove                                     |
| service_type | database                                  |
| url          | http://controller:8779/v1.0/%(tenant_id)s |
+--------------+-------------------------------------------+
[root@controller ~]# openstack endpoint create --region RegionOne database internal http://controller:8779/v1.0/%\(tenant_id\)s
+--------------+-------------------------------------------+
| Field        | Value                                     |
+--------------+-------------------------------------------+
| enabled      | True                                      |
| id           | 2d5239ea4cdf4375b7eb7f357293b562          |
| interface    | internal                                  |
| region       | RegionOne                                 |
| region_id    | RegionOne                                 |
| service_id   | 439f86cc8879428f9a25fc12d90d3982          |
| service_name | trove                                     |
| service_type | database                                  |
| url          | http://controller:8779/v1.0/%(tenant_id)s |
+--------------+-------------------------------------------+
[root@controller ~]# openstack endpoint create --region RegionOne database admin http://controller:8779/v1.0/%\(tenant_id\)s
+--------------+-------------------------------------------+
| Field        | Value                                     |
+--------------+-------------------------------------------+
| enabled      | True                                      |
| id           | 4fd7643efd52409097c9f81563595964          |
| interface    | admin                                     |
| region       | RegionOne                                 |
| region_id    | RegionOne                                 |
| service_id   | 439f86cc8879428f9a25fc12d90d3982          |
| service_name | trove                                     |
| service_type | database                                  |
| url          | http://controller:8779/v1.0/%(tenant_id)s |
+--------------+-------------------------------------------+
```

7.编辑 Trove 配置文件

```shell
[root@controller ~]# vim /etc/trove/trove.conf
[DEFAULT]
bind_host = 192.168.100.131
log_dir = /var/log/trove
network_driver = trove.network.neutron.NeutronDriver
management_security_groups = <manage security group>
nova_keypair = trove-mgmt
default_datastore = mysql
taskmanager_manager = trove.taskmanager.manager.Manager
trove_api_workers = 5
transport_url = rabbit://openstack:000000@controller:5672/
reboot_time_out = 300
usage_timeout = 900
agent_call_high_timeout = 1200
use_syslog = False
debug = True

# Set these if using Neutron Networking
network_driver=trove.network.neutron.NeutronDriver
network_label_regex=.*


[database]
connection = mysql+pymysql://trove:000000@controller/trove

[keystone_authtoken]
project_domain_name = Default
project_name = service
user_domain_name = Default
password = trove
username = trove
auth_url = http://controller:5000/v3/
auth_type = password

[service_credentials]
auth_url = http://controller:5000/v3/
region_name = RegionOne
project_name = service
password = trove
project_domain_name = Default
user_domain_name = Default
username = trove

[mariadb]
tcp_ports = 3306,4444,4567,4568

[mysql]
tcp_ports = 3306

[postgresql]
tcp_ports = 5432
```

![](https://github.com/Xiao254182/notes/blob/master/img/8/61.png)

![](https://github.com/Xiao254182/notes/blob/master/img/8/62.png)

![](https://github.com/Xiao254182/notes/blob/master/img/8/63.png)

![](https://github.com/Xiao254182/notes/blob/master/img/8/64.png)

![](https://github.com/Xiao254182/notes/blob/master/img/8/65.png)

![](https://github.com/Xiao254182/notes/blob/master/img/8/66.png)

![](https://github.com/Xiao254182/notes/blob/master/img/8/67.png)

8.编辑 `/etc/trove/trove-guestagent.conf`

```shell
[root@controller ~]# vim /etc/trove/trove-guestagent.conf
[DEFAULT]
log_file = trove-guestagent.log
log_dir = /var/log/trove/
ignore_users = os_admin
control_exchange = trove
transport_url = rabbit://openstack:000000@controller:5672/
rpc_backend = rabbit
command_process_timeout = 60
use_syslog = False
debug = True

[service_credentials]
auth_url = http://controller:5000/v3/
region_name = RegionOne
project_name = service
password = TROVE_PASS
project_domain_name = Default
user_domain_name = Default
username = trove

[mysql]
docker_image = your-registry/your-repo/mysql
backup_docker_image = your-registry/your-repo/db-backup-mysql:1.1.0
```

![](https://github.com/Xiao254182/notes/blob/master/img/8/68.png)

9.数据库同步

```shell
[root@controller ~]# su -s /bin/sh -c "trove-manage db_sync" trove
```

10.启动服务

```shell
[root@controller ~]# systemctl start openstack-trove-api.service openstack-trove-taskmanager.service openstack-trove-conductor.service && systemctl enable openstack-trove-api.service openstack-trove-taskmanager.service openstack-trove-conductor.service
Created symlink /etc/systemd/system/multi-user.target.wants/openstack-trove-api.service → /usr/lib/systemd/system/openstack-trove-api.service.
Created symlink /etc/systemd/system/multi-user.target.wants/openstack-trove-taskmanager.service → /usr/lib/systemd/system/openstack-trove-taskmanager.service.
Created symlink /etc/systemd/system/multi-user.target.wants/openstack-trove-conductor.service → /usr/lib/systemd/system/openstack-trove-conductor.service.
```

3.10 部署Swift

```
Swift 提供了一个高度可扩展的对象存储系统，用于提供对象存储服务可以存储和检索大量的非结构化数据。
```

在controller节点和storage节点部署Swift

3.10.1 controller节点

1.安装软件包

```shell
[root@controller ~]# dnf install -y openstack-swift-proxy python3-swiftclient python3-keystoneclient python3-keystonemiddleware memcached
```

2.创建用户

```shell
[root@controller ~]# source ~/.admin-openrc
[root@controller ~]# openstack user create --domain default --password-prompt swift
User Password:
Repeat User Password:
+---------------------+----------------------------------+
| Field               | Value                            |
+---------------------+----------------------------------+
| domain_id           | default                          |
| enabled             | True                             |
| id                  | ff83420ac4c748468bb4bd6219fac9df |
| name                | swift                            |
| options             | {}                               |
| password_expires_at | None                             |
+---------------------+----------------------------------+
```

3.添加 Swift 用户到 service project 并指定 admin 的 role：

```shell
[root@controller ~]# openstack role add --project service --user swift admin
```

4.创建 Swift 服务实体：

```shell
[root@controller ~]# openstack service create --name swift --description "OpenStack Objeject-store
+-------------+----------------------------------+
| Field       | Value                            |
+-------------+----------------------------------+
| description | OpenStack Object Storage         |
| enabled     | True                             |
| id          | d0ca1c6593e64bdc93b574acc45b24ed |
| name        | swift                            |
| type        | object-store                     |
+-------------+----------------------------------+       
```

5.创建服务 API 端点：

```shell
[root@controller ~]# openstack endpoint create --region RegionOne object-store public htr:8080/v1/AUTH_%\(project_id\)s
+--------------+-----------------------------------------------+
| Field        | Value                                         |
+--------------+-----------------------------------------------+
| enabled      | True                                          |
| id           | 2cfb884204a44abe84f5ced5f0151e72              |
| interface    | public                                        |
| region       | RegionOne                                     |
| region_id    | RegionOne                                     |
| service_id   | d0ca1c6593e64bdc93b574acc45b24ed              |
| service_name | swift                                         |
| service_type | object-store                                  |
| url          | http://controller:8080/v1/AUTH_%(project_id)s |
+--------------+-----------------------------------------------+
[root@controller ~]# openstack endpoint create --region RegionOne object-store internal ler:8080/v1/AUTH_%\(project_id\)s
+--------------+-----------------------------------------------+
| Field        | Value                                         |
+--------------+-----------------------------------------------+
| enabled      | True                                          |
| id           | 1be24255a9de42639890f4b73a8f6c07              |
| interface    | internal                                      |
| region       | RegionOne                                     |
| region_id    | RegionOne                                     |
| service_id   | d0ca1c6593e64bdc93b574acc45b24ed              |
| service_name | swift                                         |
| service_type | object-store                                  |
| url          | http://controller:8080/v1/AUTH_%(project_id)s |
+--------------+-----------------------------------------------+
[root@controller ~]# openstack endpoint create --region RegionOne object-store admin htt:8080/v1
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | 1349bbbcc7fc4a59a43893076e3c65e3 |
| interface    | admin                            |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | d0ca1c6593e64bdc93b574acc45b24ed |
| service_name | swift                            |
| service_type | object-store                     |
| url          | http://controller:8080/v1        |
+--------------+----------------------------------+ 
```

6.配置proxy，编辑 `/etc/swift/proxy-server.conf` 文件

```shell
[root@controller ~]# vim /etc/swift/proxy-server.conf
bind_port = 5000
password = SWIFT_PASS
```

![](https://github.com/Xiao254182/notes/blob/master/img/8/69.png)

![](https://github.com/Xiao254182/notes/blob/master/img/8/70.png)

3.10.2 storage 节点

Storage 节点要提前准备至少两块硬盘提供对象存储的能力，本文设备名称为 `/dev/sdc` 和 `/dev/sdd`

1.安装软件包

```shell
[root@storage ~]# dnf install -y openstack-swift-account openstack-swift-container openstack-swift-object xfsprogs rsync-daemon
```

2.将设备 `/dev/sdbc` 和 `/dev/sdd` 格式化为 XFS

```shell
[root@storage ~]# lsblk -l
NAME                                        MAJ:MIN RM  SIZE RO TYPE MOUNTPOINTS
sda                                           8:0    0   50G  0 disk
sda1                                          8:1    0    1M  0 part
sda2                                          8:2    0    1G  0 part /boot
sda3                                          8:3    0   49G  0 part
sdb                                           8:16   0   50G  0 disk
sdc                                           8:32   0   50G  0 disk
sdd                                           8:48   0   50G  0 disk
sr0                                          11:0    1  1.3G  0 rom
opencloudos-root                            251:0    0   49G  0 lvm  /
cinder--volumes-cinder--volumes--pool_tmeta 251:1    0   48M  0 lvm
cinder--volumes-cinder--volumes--pool_tdata 251:2    0 47.5G  0 lvm
cinder--volumes-cinder--volumes--pool       251:3    0 47.5G  0 lvm
[root@storage ~]# mkfs.xfs /dev/sdc
meta-data=/dev/sdc               isize=512    agcount=4, agsize=3276800 blks
         =                       sectsz=512   attr=2, projid32bit=1
         =                       crc=1        finobt=1, sparse=1, rmapbt=1
         =                       reflink=1    bigtime=1 inobtcount=1 nrext64=1
data     =                       bsize=4096   blocks=13107200, imaxpct=25
         =                       sunit=0      swidth=0 blks
naming   =version 2              bsize=4096   ascii-ci=0, ftype=1
log      =internal log           bsize=4096   blocks=16384, version=2
         =                       sectsz=512   sunit=0 blks, lazy-count=1
realtime =none                   extsz=4096   blocks=0, rtextents=0
[root@storage ~]# mkfs.xfs /dev/sdd
meta-data=/dev/sdd               isize=512    agcount=4, agsize=3276800 blks
         =                       sectsz=512   attr=2, projid32bit=1
         =                       crc=1        finobt=1, sparse=1, rmapbt=1
         =                       reflink=1    bigtime=1 inobtcount=1 nrext64=1
data     =                       bsize=4096   blocks=13107200, imaxpct=25
         =                       sunit=0      swidth=0 blks
naming   =version 2              bsize=4096   ascii-ci=0, ftype=1
log      =internal log           bsize=4096   blocks=16384, version=2
         =                       sectsz=512   sunit=0 blks, lazy-count=1
realtime =none                   extsz=4096   blocks=0, rtextents=0
```

3.创建挂载点目录

```shell
[root@storage ~]# mkdir -p /srv/node/sdc
[root@storage ~]# mkdir -p /srv/node/sdd
```

4.编辑 `/etc/fstab` 文件

```shell
[root@storage ~]# blkid
/dev/sdd: UUID="ad8c6724-d40e-4491-bdfc-a58cbbcb2792" BLOCK_SIZE="512" TYPE="xfs"
/dev/sdb: UUID="Zp8kXs-Y8Qx-B6SL-OuAV-x2nc-QwQR-2v804R" TYPE="LVM2_member"
/dev/sr0: BLOCK_SIZE="2048" UUID="2024-05-13-12-35-06-00" LABEL="OC-9-2-x86_64-dvd" TYPE="iso9660"
/dev/mapper/opencloudos-root: UUID="c77ea7fe-f7ff-4b2e-9487-b45a27b7501e" BLOCK_SIZE="512" TYPE="xf
/dev/sdc: UUID="571dc15f-daf9-4717-a847-cc23984346e3" BLOCK_SIZE="512" TYPE="xfs"
/dev/sda2: UUID="8a0875d8-ef79-4632-af3a-56e87fb73997" BLOCK_SIZE="512" TYPE="xfs" PARTUUID="a8453b5-60eabadc9737"
/dev/sda3: UUID="YRvacr-RKaq-fsxB-qwfr-cHtT-2tk3-ICkr6C" TYPE="LVM2_member" PARTUUID="9c388c83-b2ab3c4f8ae"
/dev/sda1: PARTUUID="a3f7c8ec-8dfd-4a93-bf65-9f8824ccb942"
[root@storage ~]# vim /etc/fstab
UUID="571dc15f-daf9-4717-a847-cc23984346e3" /srv/node/sdc         xfs     noatime         0 2 
UUID="ad8c6724-d40e-4491-bdfc-a58cbbcb2792" /srv/node/sdd         xfs     noatime         0 2
```

![](https://github.com/Xiao254182/notes/blob/master/img/8/71.png)

5.挂载设备

```shell
[root@storage ~]# mount /srv/node/sdc
mount: (hint) your fstab has been modified, but systemd still uses
       the old version; use 'systemctl daemon-reload' to reload.
[root@storage ~]# mount /srv/node/sdd
mount: (hint) your fstab has been modified, but systemd still uses
       the old version; use 'systemctl daemon-reload' to reload.
[root@storage ~]# systemctl daemon-reload
```

6.编辑 `/etc/rsyncd.conf` 文件直接输入如下内容:

```shell
[root@storage ~]# vim /etc/rsyncd.conf
[DEFAULT]
uid = swift
gid = swift
log file = /var/log/rsyncd.log
pid file = /var/run/rsyncd.pid
address = 192.168.100.133

[account]
max connections = 2
path = /srv/node/
read only = False
lock file = /var/lock/account.lock

[container]
max connections = 2
path = /srv/node/
read only = False
lock file = /var/lock/container.lock

[object]
max connections = 2
path = /srv/node/
read only = False
lock file = /var/lock/object.lock
```

![](https://github.com/Xiao254182/notes/blob/master/img/8/72.png)

7.启动rsyncd 服务

```shell
[root@storage ~]# systemctl start rsyncd.service && systemctl enable rsyncd.service
Created symlink /etc/systemd/system/multi-user.target.wants/rsyncd.service → /usr/lib/systemd/system/rsyncd.service.
```

8 配置存储节点

编辑 `/etc/swift` 目录的 `account-server.conf`、`container-server.conf` 和 `object-server.conf` 文件，替换 `bind_ip` 为存储节点上的 IP 地址。

```shell
[root@storage ~]# sed -i "s/127.0.0.1/192.168.100.133/g" /etc/swift/account-server.conf
[root@storage ~]# sed -i "s/127.0.0.1/192.168.100.133/g" /etc/swift/container-server.conf
[root@storage ~]# sed -i "s/127.0.0.1/192.168.100.133/g" /etc/swift/object-server.conf
```

确保挂载点目录结构的正确所有权

```shell
[root@storage ~]# chown -R swift:swift /srv/node
```

创建 recon 目录并确保其拥有正确的所有权

```shell
[root@storage ~]# mkdir -p /var/cache/swift
[root@storage ~]# chown -R root:swift /var/cache/swift
[root@storage ~]# chmod -R 775 /var/cache/swift
```

3.10.3 创建与分发环

```
Swift 使用环来实现高可用性和可扩展性。Swift 中的环是指一组存储对象的容器，可以存储和检索大量的非结构化数据。环由多个存储节点组成，
每个节点都可以存储和检索对象。可以自动将数据复制到多个节点上，以提高数据的可靠性和可用性。
```

创建与分发环的操作都在 controller 节点

账号环：用于存储账号信息，包括账号的元数据和访问控制信息，配置步骤如下：

1.创建基础 `account.builder` 文件

```shell
[root@controller ~]# cd /etc/swift/
[root@controller swift]# swift-ring-builder account.builder create 10 1 1
```

2.将每个存储节点添加到环中

```shell
[root@controller swift]# swift-ring-builder account.builder add --region 1 --zone 1 \
--ip 192.168.100.133 \
--port 6202  --device /dev/sdc \
--weight 100
Device d0r1z1-192.168.100.133:6202R192.168.100.133:6202//dev/sdc_"" with 100.0 weight got id 0
[root@controller swift]# swift-ring-builder account.builder add --region 1 --zone 1 \
--ip 192.168.100.133 \
--port 6202  --device /dev/sdd \
--weight 100
Device d1r1z1-192.168.100.133:6202R192.168.100.133:6202//dev/sdd_"" with 100.0 weight got id 1
```

3.验证账号环内容

```shell
[root@controller swift]# swift-ring-builder account.builder
account.builder, build version 2, id ceea1ceac43a460995a2169f37c1639f
1024 partitions, 1.000000 replicas, 1 regions, 1 zones, 2 devices, 100.00 balance, 0.00 dispersion
The minimum number of hours before a partition can be reassigned is 1 (0:00:00 remaining)
The overload factor is 0.00% (0.000000)
Ring file account.ring.gz not found, probably it hasn't been written yet
Devices:   id region zone      ip address:port  replication ip:port  name weight partitions balance flags meta
            0      1    1 192.168.100.133:6202 192.168.100.133:6202 /dev/sdc 100.00          0 -100.00
            1      1    1 192.168.100.133:6202 192.168.100.133:6202 /dev/sdd 100.00          0 -100.00
```

4.重新平衡账号环

```shell
[root@controller swift]# swift-ring-builder account.builder rebalance
Reassigned 1024 (100.00%) partitions. Balance is now 0.00.  Dispersion is now 0.00
```

容器环：用于存储容器信息，包括容器的元数据和访问控制信息。配置步骤如下：

1.创建基础 `container.builder` 文件

```shell
[root@controller swift]# cd /etc/swift
[root@controller swift]# swift-ring-builder container.builder create 10 1 1
```

2.将每个存储节点添加到环中

```shell
[root@controller swift]# swift-ring-builder container.builder add --region 1 --zone 1 \
--ip 192.168.100.133 \
--port 6201 --device /dev/sdc \
--weight 100
Device d0r1z1-192.168.100.133:6201R192.168.100.133:6201//dev/sdc_"" with 100.0 weight got id 0
[root@controller swift]# swift-ring-builder container.builder add --region 1 --zone 1 \
--ip 192.168.100.133 \
--port 6201 --device /dev/sdd \
--weight 100
Device d1r1z1-192.168.100.133:6201R192.168.100.133:6201//dev/sdd_"" with 100.0 weight got id 1
```

3.验证容器环内容

```shell
[root@controller swift]# swift-ring-builder container.builder
container.builder, build version 2, id 19f0b99d2788467e99f6d2e1c76aae89
1024 partitions, 1.000000 replicas, 1 regions, 1 zones, 2 devices, 100.00 balance, 0.00 dispersion
The minimum number of hours before a partition can be reassigned is 1 (0:00:00 remaining)
The overload factor is 0.00% (0.000000)
Ring file container.ring.gz not found, probably it hasn't been written yet
Devices:   id region zone      ip address:port  replication ip:port  name weight partitions balance flags meta
            0      1    1 192.168.100.133:6201 192.168.100.133:6201 /dev/sdc 100.00          0 -100.00
            1      1    1 192.168.100.133:6201 192.168.100.133:6201 /dev/sdd 100.00          0 -100.00
```

4.重新平衡容器环

```shell
[root@controller swift]# swift-ring-builder container.builder rebalance
Reassigned 1024 (100.00%) partitions. Balance is now 0.00.  Dispersion is now 0.00
```

对象环

1.创建基础 `object.builder` 文件

```shell
[root@controller swift]# cd /etc/swift
[root@controller swift]# swift-ring-builder object.builder create 10 1 1
```

2.将每个存储节点添加到环中

```shell
[root@controller swift]# swift-ring-builder object.builder add --region 1 --zone 1 \
--ip 192.168.100.133 \
--port 6200 --device /dev/sdc \
--weight 100
Device d0r1z1-192.168.100.133:6200R192.168.100.133:6200//dev/sdc_"" with 100.0 weight got id 0
[root@controller swift]# swift-ring-builder object.builder add --region 1 --zone 1 \
--ip 192.168.100.133 \
--port 6200 --device /dev/sdd \
--weight 100
Device d1r1z1-192.168.100.133:6200R192.168.100.133:6200//dev/sdd_"" with 100.0 weight got id 1
```

3.验证对象环内容

```shell
[root@controller swift]# swift-ring-builder object.builder
object.builder, build version 2, id 5574ab5b90d448dbb0d926030bf5d656
1024 partitions, 1.000000 replicas, 1 regions, 1 zones, 2 devices, 100.00 balance, 0.00 dispersion
The minimum number of hours before a partition can be reassigned is 1 (0:00:00 remaining)
The overload factor is 0.00% (0.000000)
Ring file object.ring.gz not found, probably it hasn't been written yet
Devices:   id region zone      ip address:port  replication ip:port  name weight partitions balance flags meta
            0      1    1 192.168.100.133:6200 192.168.100.133:6200 /dev/sdc 100.00          0 -100.00
            1      1    1 192.168.100.133:6200 192.168.100.133:6200 /dev/sdd 100.00          0 -100.00
```

4.重新平衡对象环

```shell
[root@controller swift]# swift-ring-builder object.builder rebalance
Reassigned 1024 (100.00%) partitions. Balance is now 0.00.  Dispersion is now 0.00
```

完成环创建后执行如下步骤：

1.分发环配置文件

将 `account.ring.gz`，`container.ring.gz` 以及 `object.ring.gz` 文件复制到storage 节点

```shell
[root@controller swift]# scp account.ring.gz container.ring.gz object.ring.gz root@192.168.100.133:/etc/swift
root@192.168.100.133's password:
account.ring.gz                                       100%  475   674.5KB/s   00:00
container.ring.gz                                     100%  480   666.5KB/s   00:00
object.ring.gz                                        100%  472   748.1KB/s   00:00
```

2.编辑 `/etc/swift/swift.conf` 配置文件，直接输入如下内容：

```shell
[root@controller swift]# openssl rand -hex 10
ec65381a1640e3200004
[root@controller swift]# vim /etc/swift/swift.conf
[swift-hash]
swift_hash_path_suffix = ec65381a1640e3200004
swift_hash_path_prefix = ec65381a1640e3200004

[storage-policy:0]
name = Policy-0
default = yes
```

![](https://github.com/Xiao254182/notes/blob/master/img/8/74.png)

3.将 `swift.conf` 文件复制到 `/etc/swift` **每个**storage 节点和运行代理服务的任何其他节点上的目录，本文不涉及代理服务器，复制到 storage 节点即可

```shell
[root@controller swift]# scp /etc/swift/swift.conf root@192.168.100.133:/etc/swift
root@192.168.100.133's password:
swift.conf                                            100%  155   147.4KB/s   00:00
```

4.在所有节点上，确保配置目录的正确所有权，因此要注意这一步不止要设置 controller 节点

```shell
[root@controller swift]# chown -R root:swift /etc/swift
[root@storage ~]# chown -R root:swift /etc/swift
```

3.10.4 启动服务

在controller节点上，使能对象存储代理服务及其依赖项，并将启动服务

```shell
[root@controller swift]# systemctl start openstack-swift-proxy.service memcached.service && systemctl enable openstack-swift-proxy.service memcached.service
Created symlink /etc/systemd/system/multi-user.target.wants/openstack-swift-proxy.service → /usr/lib/systemd/system/openstack-swift-proxy.service.
```

在storage节点上，使能对象存储服务并启动

```shell
[root@storage ~]# systemctl start openstack-swift-account.service \
    openstack-swift-account-auditor.service \
    openstack-swift-account-reaper.service \
    openstack-swift-account-replicator.service \
    openstack-swift-container.service \
    openstack-swift-container-auditor.service \
    openstack-swift-container-replicator.service \
    openstack-swift-container-updater.service \
    openstack-swift-object.service \
    openstack-swift-object-auditor.service \
    openstack-swift-object-replicator.service \
    openstack-swift-object-updater.service
[root@storage ~]# systemctl enable openstack-swift-account.service \
    openstack-swift-account-auditor.service \
    openstack-swift-account-reaper.service \
    openstack-swift-account-replicator.service \
    openstack-swift-container.service \
    openstack-swift-container-auditor.service \
    openstack-swift-container-replicator.service \
    openstack-swift-container-updater.service \
    openstack-swift-object.service \
    openstack-swift-object-auditor.service \
    openstack-swift-object-replicator.service \
    openstack-swift-object-updater.service
Created symlink /etc/systemd/system/multi-user.target.wants/openstack-swift-account.service → /usr/lib/systemd/system/openstack-swift-account.service.
Created symlink /etc/systemd/system/multi-user.target.wants/openstack-swift-account-auditor.service → /usr/lib/systemd/system/openstack-swift-account-auditor.service.
Created symlink /etc/systemd/system/multi-user.target.wants/openstack-swift-account-reaper.service → /usr/lib/systemd/system/openstack-swift-account-reaper.service.
Created symlink /etc/systemd/system/multi-user.target.wants/openstack-swift-account-replicator.service → /usr/lib/systemd/system/openstack-swift-account-replicator.service.
Created symlink /etc/systemd/system/multi-user.target.wants/openstack-swift-container.service → /usr/lib/systemd/system/openstack-swift-container.service.
Created symlink /etc/systemd/system/multi-user.target.wants/openstack-swift-container-auditor.service → /usr/lib/systemd/system/openstack-swift-container-auditor.service.
Created symlink /etc/systemd/system/multi-user.target.wants/openstack-swift-container-replicator.service → /usr/lib/systemd/system/openstack-swift-container-replicator.service.
Created symlink /etc/systemd/system/multi-user.target.wants/openstack-swift-container-updater.service → /usr/lib/systemd/system/openstack-swift-container-updater.service.
Created symlink /etc/systemd/system/multi-user.target.wants/openstack-swift-object.service → /usr/lib/systemd/system/openstack-swift-object.service.
Created symlink /etc/systemd/system/multi-user.target.wants/openstack-swift-object-auditor.service → /usr/lib/systemd/system/openstack-swift-object-auditor.service.
Created symlink /etc/systemd/system/multi-user.target.wants/openstack-swift-object-replicator.service → /usr/lib/systemd/system/openstack-swift-object-replicator.service.
Created symlink /etc/systemd/system/multi-user.target.wants/openstack-swift-object-updater.service → /usr/lib/systemd/system/openstack-swift-object-updater.service.
```

3.11 Cyborg 安装

```
Cyborg 用于管理和查询包括 FPGA、GPU 和 ASIC 在内的加速器资源，可以帮助用户提高应用程序的性能和效率
```

在 controller 节点部署Cyborg

1.安装软件包

```shell
[root@controller ~]# dnf install -y openstack-cyborg
```

2.创建 Cyborg 数据库并授权

```shell
[root@controller ~]# mysql -uroot -p000000
Welcome to the MariaDB monitor.  Commands end with ; or \g.
Your MariaDB connection id is 316
Server version: 10.11.4-MariaDB MariaDB Server

Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

MariaDB [(none)]> create database cyborg;
Query OK, 1 row affected (0.001 sec)

MariaDB [(none)]> grant all privileges on cyborg.* to 'cyborg'@'localhost' identified by
 '000000';
Query OK, 0 rows affected (0.003 sec)

MariaDB [(none)]> grant all privileges on cyborg.* to 'cyborg'@'%' identified by '000000';
Query OK, 0 rows affected (0.001 sec)

MariaDB [(none)]> exit
Bye
```

3.创建用户

```shell
[root@controller ~]# source ~/.admin-openrc
[root@controller ~]# openstack user create --domain default --password-prompt cyborg
User Password:
Repeat User Password:
+---------------------+----------------------------------+
| Field               | Value                            |
+---------------------+----------------------------------+
| domain_id           | default                          |
| enabled             | True                             |
| id                  | 414aba84f288446b82471f22abbf879b |
| name                | cyborg                           |
| options             | {}                               |
| password_expires_at | None                             |
+---------------------+----------------------------------+
```

4.添加 Cyborg 用户到 service project 并指定 admin 的 role：

```shell
[root@controller ~]# openstack role add --project service --user cyborg admin
```

5.创建 Cyborg 服务实体：

```shell
[root@controller ~]# openstack service create --name cyborg --description "Acceleration Service" accelerator
+-------------+----------------------------------+
| Field       | Value                            |
+-------------+----------------------------------+
| description | Acceleration Service             |
| enabled     | True                             |
| id          | 018d24a6180646f2ae894495f590d486 |
| name        | cyborg                           |
| type        | accelerator                      |
+-------------+----------------------------------+
```

6.创建服务 API 端点：

```shell
[root@controller ~]# openstack endpoint create --region RegionOne accelerator public http://controller:6666/v1
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | 695e8f0cd0e14a84acb7758620f9c957 |
| interface    | public                           |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | 018d24a6180646f2ae894495f590d486 |
| service_name | cyborg                           |
| service_type | accelerator                      |
| url          | http://controller:6666/v1        |
+--------------+----------------------------------+
[root@controller ~]# openstack endpoint create --region RegionOne accelerator internal http://controller:6666/v1
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | 0ab879fcf8bf4f3eaef0117115d226af |
| interface    | internal                         |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | 018d24a6180646f2ae894495f590d486 |
| service_name | cyborg                           |
| service_type | accelerator                      |
| url          | http://controller:6666/v1        |
+--------------+----------------------------------+
[root@controller ~]# openstack endpoint create --region RegionOne accelerator admin http://controller:6666/v1
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | bdf88f684cc04a228876413d30593afd |
| interface    | admin                            |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | 018d24a6180646f2ae894495f590d486 |
| service_name | cyborg                           |
| service_type | accelerator                      |
| url          | http://controller:6666/v1        |
+--------------+----------------------------------+
```

7 编辑 Cyborg 配置文件

```shell
[root@controller ~]# vim /etc/cyborg/cyborg.conf
[DEFAULT]
transport_url = rabbit://openstack:000000@controller
use_syslog = False
state_path = /var/lib/cyborg
debug = True

[database]
connection = mysql+pymysql://cyborg:000000@controller/cyborg

[service_catalog]
project_domain_id = default
user_domain_id = default
project_name = service
password = 000000
username = cyborg
auth_url = http://controller:5000
auth_type = password

[placement]
project_domain_name = Default
project_name = service
user_domain_name = Default
password = 000000
username = placement
auth_url = http://controller:5000/v3
auth_type = password

[keystone_authtoken]
memcached_servers = controller:11211
project_domain_name = Default
project_name = service
user_domain_name = Default
password = 000000
username = cyborg
auth_url = http://controller:5000
auth_type = password
```

![](https://github.com/Xiao254182/notes/blob/master/img/8/75.png)

![](https://github.com/Xiao254182/notes/blob/master/img/8/76.png)

![](https://github.com/Xiao254182/notes/blob/master/img/8/77.png)

![](https://github.com/Xiao254182/notes/blob/master/img/8/78.png)

8.同步数据库

```shell
[root@controller ~]# cyborg-dbsync --config-file /etc/cyborg/cyborg.conf upgrade
INFO  [alembic.runtime.migration] Context impl MySQLImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
INFO  [alembic.runtime.migration] Running upgrade  -> f50980397351, initial migration.
INFO  [alembic.runtime.migration] Running upgrade f50980397351 -> d6f033d8fa5b, add-quota-related-tables
INFO  [alembic.runtime.migration] Running upgrade d6f033d8fa5b -> ede4e3f1a232, new_db_schema
INFO  [alembic.runtime.migration] Running upgrade ede4e3f1a232 -> 589ff20545b7, add_aichip_type
INFO  [alembic.runtime.migration] Running upgrade 589ff20545b7 -> c1b5abada09c, update_for_nova_integ
INFO  [alembic.runtime.migration] Running upgrade c1b5abada09c -> 57539722e5cf, placeholder
INFO  [alembic.runtime.migration] Running upgrade 57539722e5cf -> 22fb1af2d51e, placeholder
INFO  [alembic.runtime.migration] Running upgrade 22fb1af2d51e -> 7b696fd94949, placeholder
INFO  [alembic.runtime.migration] Running upgrade 7b696fd94949 -> 62bcf2610c5d, placeholder
INFO  [alembic.runtime.migration] Running upgrade 62bcf2610c5d -> 7a4fd0fc3f8c, placeholder
INFO  [alembic.runtime.migration] Running upgrade 7a4fd0fc3f8c -> 60d8ac91fd20, add_description_field_to_dps
INFO  [alembic.runtime.migration] Running upgrade 60d8ac91fd20 -> 7e6f1f107f2b, add_qat_type
INFO  [alembic.runtime.migration] Running upgrade 7e6f1f107f2b -> 899cead40bc9, add_nic_type
INFO  [alembic.runtime.migration] Running upgrade 899cead40bc9 -> 4cc1d79978fc, add_ssd_type
```

9.使能并启动服务

```shell
[root@controller ~]# systemctl start openstack-cyborg-api openstack-cyborg-conductor openstack-cyborg-agent && systemctl enable openstack-cyborg-api openstack-cyborg-conductor openstack-cyborg-agent
Created symlink /etc/systemd/system/multi-user.target.wants/openstack-cyborg-api.service → /usr/lib/systemd/system/openstack-cyborg-api.service.
Created symlink /etc/systemd/system/multi-user.target.wants/openstack-cyborg-conductor.service → /usr/lib/systemd/system/openstack-cyborg-conductor.service.
Created symlink /etc/systemd/system/multi-user.target.wants/openstack-cyborg-agent.service → /usr/lib/systemd/system/openstack-cyborg-agent.service.
```

3.12 Aodh 安装

```
Aodh 提供了告警服务，可以帮助用户监控 OpenStack 中的各种资源，如实例、卷和镜像等，以及自定义指标，提高OpenStack的可靠性和可用性。
```

在 controller 节点部署Aodh

1.安装软件包

```shell
[root@controller ~]# dnf install -y openstack-aodh-api openstack-aodh-evaluator openstack-aodh-notifier openstack-aodh-listener openstack-aodh-expirer python3-aodhclient
```

2.创建 Aodh 数据库并授权

```shell
[root@controller ~]# mysql -uroot -p000000
Welcome to the MariaDB monitor.  Commands end with ; or \g.
Your MariaDB connection id is 325
Server version: 10.11.4-MariaDB MariaDB Server

Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

MariaDB [(none)]> create database aodh;
Query OK, 1 row affected (0.001 sec)

MariaDB [(none)]> grant all privileges on aodh.* to 'aodh'@'localhost' identified by '000000';
Query OK, 0 rows affected (0.002 sec)

MariaDB [(none)]> grant all privileges on aodh.* to 'aodh'@'%' identified by '000000';  Query OK, 0 rows affected (0.001 sec)

MariaDB [(none)]> exit
Bye
```

3.创建用户

```shell
[root@controller ~]# source ~/.admin-openrc
[root@controller ~]# openstack user create --domain default --password-prompt aodh
User Password:
Repeat User Password:
+---------------------+----------------------------------+
| Field               | Value                            |
+---------------------+----------------------------------+
| domain_id           | default                          |
| enabled             | True                             |
| id                  | e159f28a2a6e41bf99aee2540ad8b6f0 |
| name                | aodh                             |
| options             | {}                               |
| password_expires_at | None                             |
+---------------------+----------------------------------+
```

4.添加 Aodh 用户到 service project 并指定 admin 的 role：

```shell
[root@controller ~]# openstack role add --project service --user aodh admin
```

5.创建 Aodh 服务实体：

```shell
[root@controller ~]# openstack service create --name aodh --description "Telemetry" alarming
+-------------+----------------------------------+
| Field       | Value                            |
+-------------+----------------------------------+
| description | Telemetry                        |
| enabled     | True                             |
| id          | 14e90c1eade44f6587aa476523f3fe37 |
| name        | aodh                             |
| type        | alarming                         |
+-------------+----------------------------------+
```

6.创建服务 API 端点：

```shell
[root@controller ~]# openstack endpoint create --region RegionOne alarming public http://controller:8042
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | 39784077cbe34bd394da469eb3805626 |
| interface    | public                           |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | 14e90c1eade44f6587aa476523f3fe37 |
| service_name | aodh                             |
| service_type | alarming                         |
| url          | http://controller:8042           |
+--------------+----------------------------------+
[root@controller ~]# openstack endpoint create --region RegionOne alarming internal http://controller:8042
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | 7a2610a05c144edfa1d97606d3b2cb25 |
| interface    | internal                         |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | 14e90c1eade44f6587aa476523f3fe37 |
| service_name | aodh                             |
| service_type | alarming                         |
| url          | http://controller:8042           |
+--------------+----------------------------------+
[root@controller ~]# openstack endpoint create --region RegionOne alarming admin http://controller:8042
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | 36f40ab3687c401db3154d3b1cd75ca9 |
| interface    | admin                            |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | 14e90c1eade44f6587aa476523f3fe37 |
| service_name | aodh                             |
| service_type | alarming                         |
| url          | http://controller:8042           |
+--------------+----------------------------------+
```

7.编辑 Aodh 配置文件

```shell
[root@controller ~]# vim /etc/aodh/aodh.conf
[database]
connection = mysql+pymysql://aodh:000000@controller/aodh

[DEFAULT]
transport_url = rabbit://openstack:000000@controller
auth_strategy = keystone

[keystone_authtoken]
www_authenticate_uri = http://controller:5000
auth_url = http://controller:5000
memcached_servers = controller:11211
auth_type = password
project_domain_id = default
user_domain_id = default
project_name = service
username = aodh
password = 000000

[service_credentials]
auth_type = password
auth_url = http://controller:5000/v3
project_domain_id = default
user_domain_id = default
project_name = service
username = aodh
password = 000000
interface = internalURL
region_name = RegionOne
```

![](https://github.com/Xiao254182/notes/blob/master/img/8/79.png)

![](https://github.com/Xiao254182/notes/blob/master/img/8/80.png)

![](https://github.com/Xiao254182/notes/blob/master/img/8/81.png)

![](https://github.com/Xiao254182/notes/blob/master/img/8/82.png)

8.同步数据库

```shell
[root@controller ~]# aodh-dbsync
Could not load threshold
2024-07-24 18:00:45.970 277929 INFO alembic.runtime.migration [-] Context impl MySQLImpl.
2024-07-24 18:00:45.970 277929 INFO alembic.runtime.migration [-] Will assume non-transactional DDL.
```

9.启动服务

```shell
[root@controller ~]# systemctl start openstack-aodh-api.service \
      openstack-aodh-evaluator.service \
      openstack-aodh-notifier.service \
      openstack-aodh-listener.service
[root@controller ~]# systemctl enable openstack-aodh-api.service \
      openstack-aodh-evaluator.service \
      openstack-aodh-notifier.service \
      openstack-aodh-listener.service
Created symlink /etc/systemd/system/multi-user.target.wants/openstack-aodh-api.service → /usr/lib/systemd/system/openstack-aodh-api.service.
Created symlink /etc/systemd/system/multi-user.target.wants/openstack-aodh-evaluator.service → /usr/lib/systemd/system/openstack-aodh-evaluator.service.
Created symlink /etc/systemd/system/multi-user.target.wants/openstack-aodh-notifier.service → /usr/lib/systemd/system/openstack-aodh-notifier.service.
Created symlink /etc/systemd/system/multi-user.target.wants/openstack-aodh-listener.service → /usr/lib/systemd/system/openstack-aodh-listener.service.
```

3.13 Gnocchi 安装

```
Gnocchi 提供度量即服务（Metric-as-a-Service），可以帮助用户更好地管理 OpenStack 中的度量数据，如实例、卷和镜像等。
```

在controller节点部署Gnocchi 

1.安装软件包

```shell
[root@controller ~]# dnf install -y openstack-gnocchi-api openstack-gnocchi-metricd python3-gnocchiclient
```

2.创建 Gnocchi 数据库并授权

```shell
[root@controller ~]# mysql -uroot -p000000
Welcome to the MariaDB monitor.  Commands end with ; or \g.
Your MariaDB connection id is 336
Server version: 10.11.4-MariaDB MariaDB Server

Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

MariaDB [(none)]> create database gnocchi;
Query OK, 1 row affected (0.001 sec)

MariaDB [(none)]> grant all privileges on gnocchi.* to 'gnocchi'@'localhost' identified
by '000000';
Query OK, 0 rows affected (0.003 sec)

MariaDB [(none)]> grant all privileges on gnocchi.* to 'gnocchi'@'%' identified by '000000';
Query OK, 0 rows affected (0.001 sec)

MariaDB [(none)]> exit
Bye
```

3.创建用户

```shell
[root@controller ~]# source ~/.admin-openrc
[root@controller ~]# openstack user create --domain default --password-prompt gnocchi
User Password:
Repeat User Password:
+---------------------+----------------------------------+
| Field               | Value                            |
+---------------------+----------------------------------+
| domain_id           | default                          |
| enabled             | True                             |
| id                  | 641faab277624171b99886ff13d2daab |
| name                | gnocchi                          |
| options             | {}                               |
| password_expires_at | None                             |
+---------------------+----------------------------------+
```

4.添加 Gnocchi 用户到 service project 并指定 admin 的 role：

```shell
[root@controller ~]# openstack role add --project service --user gnocchi admin
```

5.创建 Gnocchi 服务实体：

```shell
[root@controller ~]# openstack service create --name gnocchi --description "Metric Service" metric
+-------------+----------------------------------+
| Field       | Value                            |
+-------------+----------------------------------+
| description | Metric Service                   |
| enabled     | True                             |
| id          | 48f87357978a463a839da8c08056de88 |
| name        | gnocchi                          |
| type        | metric                           |
+-------------+----------------------------------+
```

6.创建服务 API 端点：

```shell
[root@controller ~]# openstack endpoint create --region RegionOne metric public http://controller:8041
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | 826a18e9b1d148fa81e22f483503cfe7 |
| interface    | public                           |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | 48f87357978a463a839da8c08056de88 |
| service_name | gnocchi                          |
| service_type | metric                           |
| url          | http://controller:8041           |
+--------------+----------------------------------+
[root@controller ~]# openstack endpoint create --region RegionOne metric internal http://controller:8041
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | 870822e833a54fc9bc2df9371ee08ae7 |
| interface    | internal                         |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | 48f87357978a463a839da8c08056de88 |
| service_name | gnocchi                          |
| service_type | metric                           |
| url          | http://controller:8041           |
+--------------+----------------------------------+
[root@controller ~]# openstack endpoint create --region RegionOne metric admin http://controller:8041
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | 4338dd6386df42af81e39add9e9bc298 |
| interface    | admin                            |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | 48f87357978a463a839da8c08056de88 |
| service_name | gnocchi                          |
| service_type | metric                           |
| url          | http://controller:8041           |
+--------------+----------------------------------+
```

7.编辑 Gnocchi 配置文件

```shell
[root@controller ~]# vim /etc/gnocchi/gnocchi.conf
[api]
auth_mode = keystone
port = 8041
uwsgi_mode = http-socket

[keystone_authtoken]
auth_type = password
auth_url = http://controller:5000/v3
project_domain_name = Default
user_domain_name = Default
project_name = service
username = gnocchi
password = 000000
interface = internalURL
region_name = RegionOne

[indexer]
url = mysql+pymysql://gnocchi:000000@controller/gnocchi

[storage]
# coordination_url is not required but specifying one will improve
# performance with better workload division across workers.
# coordination_url = redis://controller:6379
file_basepath = /var/lib/gnocchi
driver = file
```

![](https://github.com/Xiao254182/notes/blob/master/img/8/83.png)

![](https://github.com/Xiao254182/notes/blob/master/img/8/84.png)

![](https://github.com/Xiao254182/notes/blob/master/img/8/85.png)

8.同步数据库

```shell
[root@controller ~]# gnocchi-upgrade
2024-07-24 18:13:52,698 [286615] INFO     gnocchi.service: Gnocchi version 4.6.0
2024-07-24 18:13:53,034 [286615] INFO     gnocchi.cli.manage: Upgrading indexer SQLAlchemyIndexer: mysql+pymysql://***:***@controller/gnocchi
2024-07-24 18:13:53,112 [286615] WARNING  py.warnings: /usr/lib/python3.11/site-packages/gnocchi/indexer/sqlalchemy.py:340: SAWarning: relationship 'ResourceHistory.metrics' will copy column resource_history.id to column metric.resource_id, which conflicts with relationship(s): 'Metric.resource' (copies resource.id to metric.resource_id), 'Resource.metrics' (copies resource.id to metric.resource_id). If this is not the intention, consider if these relationships should be linked with back_populates, or if viewonly=True should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the orm.foreign() annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter 'overlaps="metrics,resource"' to the 'ResourceHistory.metrics' relationship. (Background on this error at: https://sqlalche.me/e/14/qzyx)
  ResourceType(

2024-07-24 18:13:53,116 [286615] INFO     gnocchi.cli.manage: Upgrading storage FileStorage: /var/lib/gnocchi
2024-07-24 18:13:53,118 [286615] INFO     gnocchi.cli.manage: Upgrading incoming storage FileStorage: /var/lib/gnocchi
```

9.启动服务

```shell
[root@controller ~]# systemctl start openstack-gnocchi-api.service openstack-gnocchi-metricd.service && systemctl enable openstack-gnocchi-api.service openstack-gnocchi-metricd.service
Created symlink /etc/systemd/system/multi-user.target.wants/gnocchi-api.service → /usr/lib/systemd/system/gnocchi-api.service.
Created symlink /etc/systemd/system/multi-user.target.wants/gnocchi-metricd.service → /usr/lib/systemd/system/gnocchi-metricd.service.
```

3.14 Ceilometer 安装

```
Ceilometer 提供计量即服务（Metering-as-a-Service）可以帮助用户更好地监控和管理 OpenStack 中的资源
```

在controller节点和compute节点部署Ceilometer，并且依赖 Gnocchi 组件

3.14.1 controller 节点

1.安装软件包

```shell
[root@controller ~]# dnf install -y openstack-ceilometer-notification openstack-ceilometer-central
```

2.创建用户

```shell
[root@controller ~]# source ~/.admin-openrc
[root@controller ~]# openstack user create --domain default --password-prompt ceilometer
User Password:
Repeat User Password:
+---------------------+----------------------------------+
| Field               | Value                            |
+---------------------+----------------------------------+
| domain_id           | default                          |
| enabled             | True                             |
| id                  | bdb6b2bfc5824ce399552a86a958d8f2 |
| name                | ceilometer                       |
| options             | {}                               |
| password_expires_at | None                             |
+---------------------+----------------------------------+
```

3.添加 Ceilometer 用户到 service project 并指定 admin 的 role：

```shell
[root@controller ~]# openstack role add --project service --user ceilometer admin
```

4.创建 Ceilometer 服务实体：

```shell
[root@controller ~]# openstack service create --name ceilometer --description "Telemetry" metering
+-------------+----------------------------------+
| Field       | Value                            |
+-------------+----------------------------------+
| description | Telemetry                        |
| enabled     | True                             |
| id          | b420ecee010b462f88577590b8e01514 |
| name        | ceilometer                       |
| type        | metering                         |
+-------------+----------------------------------+
```

5.编辑配置文件 `/etc/ceilometer/pipeline.yaml`

```shell
[root@controller ~]# vim /etc/ceilometer/pipeline.yaml
publishers:
      # set address of Gnocchi
      # + filter out Gnocchi-related activity meters (Swift driver)
      # + set default archive policy
      - gnocchi://?filter_project=service&archive_policy=low
```

![](https://github.com/Xiao254182/notes/blob/master/img/8/86.png)

6.编辑配置文件 `/etc/ceilometer/ceilometer.conf`

```shell
[root@controller ~]# vim /etc/ceilometer/ceilometer.conf
[DEFAULT]
transport_url = rabbit://openstack:000000@controller

[service_credentials]
auth_type = password
auth_url = http://controller:5000/v3
project_domain_id = default
user_domain_id = default
project_name = service
username = ceilometer
password = 000000
interface = internalURL
region_name = RegionOne
```

![](https://github.com/Xiao254182/notes/blob/master/img/8/87.png)

![](https://github.com/Xiao254182/notes/blob/master/img/8/88.png)

7.数据库同步

```shell
[root@controller ~]# ceilometer-upgrade
```

8.启动服务

```shell
[root@controller ~]# systemctl start openstack-ceilometer-notification.service openstack-ceilometer-central.service && systemctl enable openstack-ceilometer-notification.service openstack-ceilometer-central.service
Created symlink /etc/systemd/system/multi-user.target.wants/openstack-ceilometer-notification.service → /usr/lib/systemd/system/openstack-ceilometer-notification.service.
Created symlink /etc/systemd/system/multi-user.target.wants/openstack-ceilometer-central.service → /usr/lib/systemd/system/openstack-ceilometer-central.service.
```

3.14.2 compute 节点

1.安装软件包

```shell
[root@compute ~]# dnf install -y openstack-ceilometer-compute
```

2.编辑配置文件 `/etc/ceilometer/ceilometer.conf`

```shell
[root@compute ~]# vim /etc/ceilometer/ceilometer.conf
[DEFAULT]
transport_url = rabbit://openstack:000000@controller

[service_credentials]
auth_url = http://controller:5000
project_domain_id = default
user_domain_id = default
auth_type = password
username = ceilometer
project_name = service
password = 000000
interface = internalURL
region_name = RegionOne
```

![](https://github.com/Xiao254182/notes/blob/master/img/8/89.png)

![](https://github.com/Xiao254182/notes/blob/master/img/8/90.png)

3.编辑配置文件 `/etc/nova/nova.conf`

```shell
[root@compute ~]# vim /etc/nova/nova.conf
[DEFAULT]
instance_usage_audit = True
instance_usage_audit_period = hour

[notifications]
notify_on_state_change = vm_and_task_state

[oslo_messaging_notifications]
driver = messagingv2
```

![](https://github.com/Xiao254182/notes/blob/master/img/8/91.png)

![](https://github.com/Xiao254182/notes/blob/master/img/8/92.png)

![](https://github.com/Xiao254182/notes/blob/master/img/8/93.png)

4.启动服务

```shell
[root@compute ~]# systemctl start openstack-ceilometer-compute.service
[root@compute ~]# systemctl enable openstack-ceilometer-compute.service
Created symlink /etc/systemd/system/multi-user.target.wants/openstack-ceilometer-compute.service → /usr/lib/systemd/system/openstack-ceilometer-compute.service.
```

5.重启 nova-compute 服务

```shell
[root@compute ~]# systemctl restart openstack-nova-compute.service
```

3.15 Heat 安装

```
Heat 提供基础设施即服务（IaaS）的编排服务，通过一组 API 和命令行工具，用于创建、更新和删除 OpenStack 中的资源
```

在controller节点部署Heat

1.安装软件包

```shell
[root@controller ~]# dnf install -y openstack-heat-api openstack-heat-api-cfn openstack-heat-engine
```

2.创建 Heat 数据库并授权

```shell
[root@controller ~]# mysql -u root -p000000
Welcome to the MariaDB monitor.  Commands end with ; or \g.
Your MariaDB connection id is 204
Server version: 10.11.4-MariaDB MariaDB Server

Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

MariaDB [(none)]> create database heat;
Query OK, 1 row affected (0.000 sec)

MariaDB [(none)]> grant all privileges on heat.* to 'heat'@'localhost' identified by '000000';
Query OK, 0 rows affected (0.019 sec)

MariaDB [(none)]> grant all privileges on heat.* to 'heat'@'%' identified by '000000';
Query OK, 0 rows affected (0.002 sec)

MariaDB [(none)]> exit
Bye
```

3.创建用户

```shell
[root@controller ~]# source ~/.admin-openrc
[root@controller ~]# openstack user create --domain default --password-prompt heat
User Password:
Repeat User Password:
+---------------------+----------------------------------+
| Field               | Value                            |
+---------------------+----------------------------------+
| domain_id           | default                          |
| enabled             | True                             |
| id                  | 828e30ff95e24ea090077e843975b55f |
| name                | heat                             |
| options             | {}                               |
| password_expires_at | None                             |
+---------------------+----------------------------------+
```

4.添加 Heat 用户到 service project 并指定 admin 的 role：

```shell
[root@controller ~]# openstack role add --project service --user heat admin
```

5.创建 heat 和 heat-cfn 服务

```shell
[root@controller ~]# openstack service create --name heat --description "Orchestration" orchestration
+-------------+----------------------------------+
| Field       | Value                            |
+-------------+----------------------------------+
| description | Orchestration                    |
| enabled     | True                             |
| id          | 1b15091b86384122ab793baafe7913ea |
| name        | heat                             |
| type        | orchestration                    |
+-------------+----------------------------------+
[root@controller ~]# openstack service create --name heat-cfn --description "Orchestration"  cloudformation
+-------------+----------------------------------+
| Field       | Value                            |
+-------------+----------------------------------+
| description | Orchestration                    |
| enabled     | True                             |
| id          | b071fab5d1e447cf88669a5b31ed36f1 |
| name        | heat-cfn                         |
| type        | cloudformation                   |
+-------------+----------------------------------+
```

6.创建服务 API 端点：

```shell
[root@controller ~]# openstack endpoint create --region RegionOne orchestration public http://controller:8004/v1/%\(tenant_id\)s
+--------------+-----------------------------------------+
| Field        | Value                                   |
+--------------+-----------------------------------------+
| enabled      | True                                    |
| id           | 824034fe2dbe47799682922e94f3d205        |
| interface    | public                                  |
| region       | RegionOne                               |
| region_id    | RegionOne                               |
| service_id   | 1b15091b86384122ab793baafe7913ea        |
| service_name | heat                                    |
| service_type | orchestration                           |
| url          | http://controller:8004/v1/%(tenant_id)s |
+--------------+-----------------------------------------+
[root@controller ~]# openstack endpoint create --region RegionOne orchestration internal http://controller:8004/v1/%\(tenant_id\)s
+--------------+-----------------------------------------+
| Field        | Value                                   |
+--------------+-----------------------------------------+
| enabled      | True                                    |
| id           | 206f6337e7264fca9d9c10bf41258686        |
| interface    | internal                                |
| region       | RegionOne                               |
| region_id    | RegionOne                               |
| service_id   | 1b15091b86384122ab793baafe7913ea        |
| service_name | heat                                    |
| service_type | orchestration                           |
| url          | http://controller:8004/v1/%(tenant_id)s |
+--------------+-----------------------------------------+
[root@controller ~]# openstack endpoint create --region RegionOne orchestration admin http://controller:8004/v1/%\(tenant_id\)s
+--------------+-----------------------------------------+
| Field        | Value                                   |
+--------------+-----------------------------------------+
| enabled      | True                                    |
| id           | 020361c0571e453fb42c69dbdbae6373        |
| interface    | admin                                   |
| region       | RegionOne                               |
| region_id    | RegionOne                               |
| service_id   | 1b15091b86384122ab793baafe7913ea        |
| service_name | heat                                    |
| service_type | orchestration                           |
| url          | http://controller:8004/v1/%(tenant_id)s |
+--------------+-----------------------------------------+
[root@controller ~]# openstack endpoint create --region RegionOne cloudformation public http://controller:8000/v1
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | edd4d8150aca4b5ea97c5644eae179d3 |
| interface    | public                           |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | b071fab5d1e447cf88669a5b31ed36f1 |
| service_name | heat-cfn                         |
| service_type | cloudformation                   |
| url          | http://controller:8000/v1        |
+--------------+----------------------------------+
[root@controller ~]# openstack endpoint create --region RegionOne cloudformation internal http://controller:8000/v1
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | db074217e64d49459c5f932593780521 |
| interface    | internal                         |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | b071fab5d1e447cf88669a5b31ed36f1 |
| service_name | heat-cfn                         |
| service_type | cloudformation                   |
| url          | http://controller:8000/v1        |
+--------------+----------------------------------+
[root@controller ~]# openstack endpoint create --region RegionOne cloudformation admin http://controller:8000/v1
+--------------+----------------------------------+
| Field        | Value                            |
+--------------+----------------------------------+
| enabled      | True                             |
| id           | 0128a7dd7c93429d813fce790db23769 |
| interface    | admin                            |
| region       | RegionOne                        |
| region_id    | RegionOne                        |
| service_id   | b071fab5d1e447cf88669a5b31ed36f1 |
| service_name | heat-cfn                         |
| service_type | cloudformation                   |
| url          | http://controller:8000/v1        |
+--------------+----------------------------------+
```

7.创建 stack 管理的账户，包括 heatdomain 及其对应 domain 的 admin 用户 heat_domain_admin， heat_stack_owner 角色，heat_stack_user 角色

```shell
[root@controller ~]# openstack user create --domain default --password-prompt heat_domain_admin
User Password:
Repeat User Password:
+---------------------+----------------------------------+
| Field               | Value                            |
+---------------------+----------------------------------+
| domain_id           | default                          |
| enabled             | True                             |
| id                  | 19a73d6cf96f41fcbe11b0ba66b6f3da |
| name                | heat_domain_admin                |
| options             | {}                               |
| password_expires_at | None                             |
+---------------------+----------------------------------+
[root@controller ~]# openstack role add --domain default --user-domain default --user heat_domain_admin admin
[root@controller ~]# openstack role create heat_stack_owner
+-------------+----------------------------------+
| Field       | Value                            |
+-------------+----------------------------------+
| description | None                             |
| domain_id   | None                             |
| id          | 328dac3f537143a8bf035417abc489e9 |
| name        | heat_stack_owner                 |
| options     | {}                               |
+-------------+----------------------------------+
[root@controller ~]# openstack role create heat_stack_user
+-------------+----------------------------------+
| Field       | Value                            |
+-------------+----------------------------------+
| description | None                             |
| domain_id   | None                             |
| id          | 97516a6f30544fed9aa3b49097d810a5 |
| name        | heat_stack_user                  |
| options     | {}                               |
+-------------+----------------------------------+
```

8.编辑配置文件 `/etc/heat/heat.conf`

```shell
[root@controller ~]# vim /etc/heat/heat.conf
[DEFAULT]
transport_url = rabbit://openstack:000000@controller
heat_metadata_server_url = http://controller:8000
heat_waitcondition_server_url = http://controller:8000/v1/waitcondition
stack_domain_admin = heat_domain_admin
stack_domain_admin_password = 000000
stack_user_domain_name = heat

[database]
connection = mysql+pymysql://heat:000000@controller/heat

[keystone_authtoken]
www_authenticate_uri = http://controller:5000
auth_url = http://controller:5000
memcached_servers = controller:11211
auth_type = password
project_domain_name = default
user_domain_name = default
project_name = service
username = heat
password = 000000

[trustee]
auth_type = password
auth_url = http://controller:5000
username = heat
password = 000000
user_domain_name = default

[clients_keystone]
auth_uri = http://controller:5000
```

![](https://github.com/Xiao254182/notes/blob/master/img/8/94.png)

![](https://github.com/Xiao254182/notes/blob/master/img/8/95.png)

![](https://github.com/Xiao254182/notes/blob/master/img/8/96.png)

![](https://github.com/Xiao254182/notes/blob/master/img/8/97.png)

![](https://github.com/Xiao254182/notes/blob/master/img/8/98.png)

9.同步数据库

```shell
[root@controller ~]# su -s /bin/sh -c "heat-manage db_sync" heat
2024-07-24 20:11:35.024 55911 INFO migrate.versioning.api [-] 72 -> 73...
2024-07-24 20:11:35.162 55911 INFO migrate.versioning.api [-] done
2024-07-24 20:11:35.162 55911 INFO migrate.versioning.api [-] 73 -> 74...
2024-07-24 20:11:35.166 55911 INFO migrate.versioning.api [-] done
2024-07-24 20:11:35.166 55911 INFO migrate.versioning.api [-] 74 -> 75...
2024-07-24 20:11:35.170 55911 INFO migrate.versioning.api [-] done
2024-07-24 20:11:35.170 55911 INFO migrate.versioning.api [-] 75 -> 76...
2024-07-24 20:11:35.173 55911 INFO migrate.versioning.api [-] done
2024-07-24 20:11:35.173 55911 INFO migrate.versioning.api [-] 76 -> 77...
2024-07-24 20:11:35.177 55911 INFO migrate.versioning.api [-] done
2024-07-24 20:11:35.177 55911 INFO migrate.versioning.api [-] 77 -> 78...
2024-07-24 20:11:35.180 55911 INFO migrate.versioning.api [-] done
2024-07-24 20:11:35.180 55911 INFO migrate.versioning.api [-] 78 -> 79...
2024-07-24 20:11:35.231 55911 INFO migrate.versioning.api [-] done
2024-07-24 20:11:35.231 55911 INFO migrate.versioning.api [-] 79 -> 80...
2024-07-24 20:11:35.259 55911 INFO migrate.versioning.api [-] done
2024-07-24 20:11:35.259 55911 INFO migrate.versioning.api [-] 80 -> 81...
2024-07-24 20:11:35.262 55911 INFO migrate.versioning.api [-] done
2024-07-24 20:11:35.262 55911 INFO migrate.versioning.api [-] 81 -> 82...
2024-07-24 20:11:35.266 55911 INFO migrate.versioning.api [-] done
2024-07-24 20:11:35.266 55911 INFO migrate.versioning.api [-] 82 -> 83...
2024-07-24 20:11:35.269 55911 INFO migrate.versioning.api [-] done
2024-07-24 20:11:35.269 55911 INFO migrate.versioning.api [-] 83 -> 84...
2024-07-24 20:11:35.272 55911 INFO migrate.versioning.api [-] done
2024-07-24 20:11:35.272 55911 INFO migrate.versioning.api [-] 84 -> 85...
2024-07-24 20:11:35.275 55911 INFO migrate.versioning.api [-] done
2024-07-24 20:11:35.275 55911 INFO migrate.versioning.api [-] 85 -> 86...
2024-07-24 20:11:35.316 55911 INFO migrate.versioning.api [-] done
```

10.启动服务

```shell
[root@controller ~]# systemctl start openstack-heat-api.service openstack-heat-api-cfn.service openstack-heat-engine.service && systemctl enable openstack-heat-api.service openstack-heat-api-cfn.service openstack-heat-engine.service
Created symlink /etc/systemd/system/multi-user.target.wants/openstack-heat-api.service → /usr/lib/systemd/system/openstack-heat-api.service.
Created symlink /etc/systemd/system/multi-user.target.wants/openstack-heat-api-cfn.service → /usr/lib/systemd/system/openstack-heat-api-cfn.service.
Created symlink /etc/systemd/system/multi-user.target.wants/openstack-heat-engine.service → /usr/lib/systemd/system/openstack-heat-engine.service.
```
