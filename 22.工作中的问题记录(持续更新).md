## 22.工作中的问题记录(持续更新)

### 1.修改Docker默认镜像和容器存储位置

Docker默认安装的情况下，会使用 `/var/lib/docker/` 目录作为存储目录，用以存放拉取的镜像和创建的容器等。不过一般生产环境下都是直接为docker的存储专门挂载一个盘的，因为需要修改docker的存储位置。

#### （1）在docker启动前（未开始使用前）修改存储位置

这里有两种修改方式，按照docker版本来的

`--graph` 选项是 Docker 早期版本中用于指定 Docker 存储位置的选项。在 Docker 17.05 版本之前，`--graph` 是一个有效的命令行参数。

从 **Docker 17.05** 开始，`--graph` 被标记为已废弃（deprecated），并被替换为 `--data-root` 参数。功能相同，都是用来指定 Docker 的存储位置。

所以，以下是关键点：

- Docker **17.05** 之前：使用 `--graph`或`-g`参数指定存储位置。

  编辑docker配置文件`/usr/lib/systemd/system/docker.service`

  ```json
  ExecStart=/usr/bin/dockerd --graph /data/docker
  ```

  ![](https://github.com/Xiao254182/Notes/blob/master/img/22/1.png)然后修改完成后重新加载配置文件并重启docker服务

  ```shell
  # reload配置文件 
  systemctl daemon-reload 
   
  # 重启docker
  systemctl restart docker.service
  ```

- Docker **17.05 及以后**：改用 `--data-root`。

   如果你使用的是较新版本的 Docker，应使用 `--data-root` 来配置存储位置。配置方式可以通过编辑 Docker     配置文件（通常是 `/etc/docker/daemon.json`）来完成，例如：

  ```json
  {
    "data-root": "/data/docker"
  }
  ```

  然后重启 Docker 服务：

  ```shell
  systemctl restart docker
  ```

此时，你会在你选择的docker存储路径中看到docker相关的内容，而且容器成功存储在我们想要的存储目录
![](https://github.com/Xiao254182/Notes/blob/master/img/22/2.png)

![](https://github.com/Xiao254182/Notes/blob/master/img/22/3.png)

#### （2）已经使用docker后修改存储位置

如果已经有容器运行中并且将数据存储在其他目录下，此时我们再按照上述方式修改docker的存储位置

![](https://github.com/Xiao254182/Notes/blob/master/img/22/4.png)

我们会发现以前存在的容器和镜像都不见了，此时我们还需要将以前的数据迁移到新的存储位置，这里推荐使用`rsync`命令进行数据同步

```bash
rsync -avzHP /data/docker /data2/

-a (archive)
归档模式，确保保留文件的权限、时间戳、符号链接、所有者和组等元信息且递归地复制目录及其内容。

-v (verbose)
显示详细输出，让用户了解同步过程中的文件操作情况。

-z (compress)
在传输过程中压缩数据，减少网络传输量。对于本地复制，压缩不会有显著效果，但可保留习惯。

-H (hard-links)
保留硬链接，确保硬链接在目标位置也被正确复制，而不会转化为独立文件。

-P (progress + partial)
显示传输进度信息。如果传输中断，保留已传输的部分文件，后续可以继续传输而不必重新开始。
```

同步完成再次查看，此时我们的镜像和容器都回来了

![](https://github.com/Xiao254182/Notes/blob/master/img/22/5.png)

确认无误后便可删除以前的docker存储目录

（PS：为什么同步docker存储数据时使用rsync命令而不用mv，cp等同样可以转移数据的命令？

为什么用 `rsync` 比 `mv` 和 `cp` 更好？

1. 增量复制

- `rsync`：
  - 支持增量复制，仅同步源和目标之间的差异部分。
  - 在迁移大量文件时（如 Docker 存储目录），可以显著减少时间和资源消耗。
- `mv` 和 `cp`：
  - 每次都将所有文件移动或复制，效率较低。

2. 数据完整性

- `rsync`：
  - 内置校验机制，确保数据传输的准确性，防止文件损坏。
- `mv` 和 `cp`：
  - 缺乏自动校验，可能导致传输过程中文件损坏却不被发现。

3. 中断恢复

- `rsync`：
  - 如果迁移中断（如网络问题、系统崩溃），可以继续未完成的部分，不需要重新开始。
- `mv` 和 `cp`：
  - 中断后需要重新移动或复制，尤其在处理大文件时非常耗时。

4. 保留文件元数据

- `rsync`：
  - 自动保留权限、所有者、时间戳等元数据。
- `cp`：
  - 必须指定 `-a` 参数才能保留元数据。
- `mv`：
  - 数据迁移后，元数据通常可以保留，但在跨分区移动时可能会丢失元数据。

5. 灵活性

- `rsync`：
  - 可用于本地和远程数据传输。
  - 支持并发传输和限速。
- `mv` 和 `cp`：
  - 只能用于本地文件操作，不适合远程操作。

）

### （3）在K8S中修改Docker默认镜像和容器存储位置

在k8s集群中，当你创建一个 Pod，Kubernetes 的运行时（例如 Docker 或 Containerd，此处只考虑docker为容器运行时）会为这个 Pod 创建以下两个容器：

1. **Pause 容器**（`k8s_POD_*`）：
   - **作用**：它是一个基础容器，用于维持 Pod 的网络和命名空间 (Namespace)。
   - **特性**：Pause 容器本身几乎不消耗资源，只是运行一个简单的挂起进程。
   - 用途：
     - 为整个 Pod 提供统一的网络栈。
     - 管理 Pod 中所有应用容器共享的网络命名空间、文件系统挂载和 IPC。
     - 在 Pod 内的多个容器可以通过 Pause 容器提供的网络命名空间进行通信。
     - 当 Pause 容器运行时，它确保 Pod 的生命周期存在，即使应用容器意外退出，Pod 的网络和其他基础设施仍然保持稳定。
2. **应用容器**（例如你的 nginx 容器）：
   - **作用**：运行用户指定的业务应用（如 nginx、MySQL 等）。
   - **特性**：它依赖于 Pause 容器提供的网络命名空间和挂载点。
   - **用途**：执行 Pod 的主要业务逻辑，比如处理 HTTP 请求或运行计算任务。

![](https://github.com/Xiao254182/Notes/blob/master/img/22/6.png)

在k8s集群中,当你用 `kubectl` 提交一个 Pod 资源时，Kubernetes 调度器会决定哪个节点运行这个 Pod，然后调度器将任务发送给该节点上的 kubelet。

kubelet 使用 CRI 接口调用 Docker，先启动一个 Pause 容器作为 Pod 的基础，然后 kubelet 启动应用容器，将其附加到 Pause 容器的网络和其他命名空间中。并且kubelet 持续监控 Pod 中的所有容器，并在容器崩溃时尝试重启。如果需要更新 Pod（例如拉取新镜像），kubelet 也会通过 Docker 完成。

所以在k8s集群中docker不在作为一个“master”的身份被用户使用，而是在docker的基础上进一步封装成kubelet调度的“slave”。因此当修改docker的默认存储地址后，不应该是用户来重启docker中的容器，而是用kubelet来调度docker达到重启容器的目的，不然会出现kubelet找不到对应的容器从而调度不到容器，导致容器被k8s集群忽略在外。

以下为在K8S中修改Docker默认镜像和容器存储位置的方法
关闭`kubelet`服务,然后关闭`docker`服务（顺序一定不能错）

```shell
systemctl stop kubelet.service && systemctl stop docker.socket && systemctl stop docker
```

![](https://github.com/Xiao254182/Notes/blob/master/img/22/8.png)

（这个警告是因为你的系统上启用了 `docker.socket` 服务，该服务负责监听 Docker 的 UNIX 套接字（通常是 `/var/run/docker.sock`）。即使你停止了 `docker.service`，`docker.socket` 仍会保持运行，这会导致`Docker`被重新激活，因此需要先停止`docker.socket`服务才能停止`docker`服务）

修改docker的存储路径并同步数据

![](https://github.com/Xiao254182/Notes/blob/master/img/22/9.png)

修改`kubelet`的配置文件，因为`kubelet`默认读取`docker`存储的目录正是`docker`默认的存储路径`/var/lib/docker`,因此`docker`修改存储路径后，`kubelet`的寻址地址也要默认修改

```shell
vim /usr/lib/systemd/system/kubelet.service.d/10-kubeadm.conf

#添加这一条
Environment="KUBELET_EXTRA_ARGS=--docker-root=<修改后的docker存储路径>"
```

![](https://github.com/Xiao254182/Notes/blob/master/img/22/10.png)

此时我们先启动`docker`服务并查看容器状态

```shell
systemctl restart docker && docker ps -a
```

![](https://github.com/Xiao254182/Notes/blob/master/img/22/11.png)

容器全部处于停止状态，此时我们千万不要使用`docker restart $(docker ps -a -q)`这种命令去启动`docker`容器，而是启动`kubelet`服务

```shell
systemctl restart kubelet
```

此时我们发现，`docker`中停止的容器被`kubelet`调度起来，且在k8s集群中也可以看到我们的服务没有丢失

![](https://github.com/Xiao254182/Notes/blob/master/img/22/12.png)

### 2.Harbor正确密码登录不上去

![](https://github.com/Xiao254182/Notes/blob/master/img/22/13.png)

明明用户名密码都正确，但就是登陆不上，这是因为`assword_version`加密版本错了，重置密码并将`sha256`改成`sha1`就可以了

```shell
docker ps -a
```

![](https://github.com/Xiao254182/Notes/blob/master/img/22/14.png)

修改`harbor`的数据库`harbor-db`

```shell
# 进入数据库容器
[root@node-1 harbor]# docker exec -it harbor-db /bin/bash

# 连接到 PostgreSQL 数据库
postgres [ / ]$ psql -h postgresql -d postgres -U postgres
Password for user postgres:
psql (13.7)
Type "help" for help.

# 切换到 registry 数据库
postgres=# \c registry
You are now connected to database "registry" as user "postgres".

# 查看用户表
registry=# select * from harbor_user;
 user_id | username  | email |             password             |    realname    |    comment     | deleted | reset_uuid |               salt               | sysadmin_flag
tion_time        |        update_time         | password_version
---------+-----------+-------+----------------------------------+----------------+----------------+---------+------------+----------------------------------+---------------
-----------------+----------------------------+------------------
       2 | anonymous |       |                                  | anonymous user | anonymous user | t       |            |                                  | f
 03:28:33.834822 | 2024-12-08 03:28:33.996368 | sha1
       1 | admin     |       | 9544276e22c04687565bd8d22b10dae8 | system admin   | admin user     | f       |            | jBTtq5qXXMeIu17bDc3ibJEewhzeMrdw | t
 03:28:33.834822 | 2024-12-08 03:28:34.204601 | sha256
(2 rows)

#  更新管理员账户密码
registry=# update harbor_user set password='a71a7d0df981a61cbb53a97ed8d78f3e', salt='ah3fdh5b7yxepalg9z45bu8zb36sszmr', password_version='sha1' where username='admin';
UPDATE 1
(PS:此处是把admin密码修改为了Harbor12345，如果想修改成其他密码，请查看下方补充)

registry=# select * from harbor_user;
 user_id | username  | email |             password             |    realname    |    comment     | deleted | reset_uuid |               salt               | sysadmin_flag
tion_time        |        update_time         | password_version
---------+-----------+-------+----------------------------------+----------------+----------------+---------+------------+----------------------------------+---------------
-----------------+----------------------------+------------------
       2 | anonymous |       |                                  | anonymous user | anonymous user | t       |            |                                  | f
 03:28:33.834822 | 2024-12-08 03:28:33.996368 | sha1
       1 | admin     |       | a71a7d0df981a61cbb53a97ed8d78f3e | system admin   | admin user     | f       |            | ah3fdh5b7yxepalg9z45bu8zb36sszmr | t
 03:28:33.834822 | 2024-12-08 03:46:27.257316 | sha1
(2 rows)

# 退出 PostgreSQL
registry=# \q
postgres [ / ]$ exit
exit
[root@node-1 harbor]# docker restart harbor-core
harbor-core
```

再次输入账户admin，密码Harbor12345，登录成功

补充：

Harbor 的密码是通过一个加密哈希算法（如 `sha1` 或 `sha256`）结合 `salt`（盐值）生成的哈希值进行存储的。因此，仅修改哈希值本身并不会直接设置明文密码。您需要知道以下内容：

- 哈希值：密码经过加密后的字符串。
- Salt：加密时使用的随机字符串，通常会与密码一起使用来增强安全性。

如何将密码设置为其他明文密码

为了通过修改数据库中的哈希值来设置密码，您需要执行以下操作：

1. 生成明文密码的哈希值

例如，假设您想将密码设置为 `000000`，您需要先生成 `000000` 密码的加密哈希值，并且使用合适的 `salt`。

步骤：

- 步骤 1：生成密码 `000000` 和一个 `salt` 的组合（比如 `randomsalt`）。
- 步骤 2：通过 SHA1 或 SHA256 算法加密密码和 Salt 组合。
- 步骤 3：用生成的哈希值和 Salt 更新数据库。

示例：

使用 Python 来生成哈希值：

```python
import hashlib

# 明文密码和盐值
password = "000000" 
salt = "randomsalt"  # 您可以自定义 Salt

# 生成 SHA1 哈希
hashed_password = hashlib.sha1((password + salt).encode()).hexdigest()
print("Generated Hashed Password:", hashed_password)
print("Salt:", salt)
```

输出：

```
Hashed Password: 5d41402abc4b2a76b9719d911017c592
Salt: randomsalt
```

使用 `openssl` 生成哈希值

```shell
bash复制代码#!/bin/bash

# 明文密码
PASSWORD="000000"

# 盐值
SALT="randomsalt"

# 生成哈希值
HASH=$(echo -n "${PASSWORD}${SALT}" | openssl dgst -sha1 | awk '{print $2}')

echo "Hashed Password: $HASH"
echo "Salt: $SALT"
```

运行结果：

```
Hashed Password: 5d41402abc4b2a76b9719d911017c592
Salt: randomsalt
```

2. 更新数据库

将 `5d41402abc4b2a76b9719d911017c592` 作为密码哈希值，`randomsalt` 作为 Salt 更新到 `harbor_user` 表：

```postgresql
update harbor_user
set password='5d41402abc4b2a76b9719d911017c592', 
    salt='randomsalt', 
    password_version='sha1'
where username='admin';
```

3. 重启 Harbor 服务

更新密码后，您需要重启 `harbor-core` 服务以使更改生效：

```
docker restart harbor-core
```

4. 登录验证

此时，您可以尝试使用用户名 `admin` 和密码 `000000` 登录 Harbor。

### 3.直接使用软件包安装docker

下载安装包

```
https://download.docker.com/linux/static/stable/
```

（PS:需要选择响应平台架构的软件包）

解压安装包并将解压之后的docker文件移到 /usr/bin目录下

```shell
tar -zxvf docker-24.0.6.tgz && cp docker/* /usr/bin/
```

将docker注册成系统服务

```shell
#vim /etc/systemd/system/docker.service

[Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
After=network-online.target firewalld.service
Wants=network-online.target

[Service]
Type=notify
ExecStart=/usr/bin/dockerd
ExecReload=/bin/kill -s HUP $MAINPID
LimitNOFILE=infinity
LimitNPROC=infinity
TimeoutStartSec=0
Delegate=yes
KillMode=process
Restart=on-failure
StartLimitBurst=3
StartLimitInterval=60s

[Install]
WantedBy=multi-user.target
```

给文件增加可执行权限

```shell
chmod +x /etc/systemd/system/docker.service
systemctl daemon-reload 
```

设置开机自启动

```shell
systemctl enable docker.service
```

启动docker

```shell
systemctl start docker
```

### 4.nexus清理磁盘空间

(工具下载地址：https://github.com/Xiao254182/Notes/blob/master/img/22/nexus-cli)

PS:这是个开源的工具，但是网上好多下载地址都挂了，这是我自己编译的，也可以根据需要自行修改(https://github.com/sonatype-nexus-community/nexus-cli)

```shell
# 配置
nexus-cli configure

# 仓库地址
Enter Nexus Host: http://127.0.0.1:8081

# 仓库名称
Enter Nexus Repository Name: docker-repo

# 账号
Enter Nexus Username: admin

# 密码
Enter Nexus Password: admin123

# 查出所有镜像
nexus-cli image ls

# 查看某一镜像的所有的 tag
nexus-cli image tags -name imagename

# 查看某一镜像详细信息
nexus-cli image info -name imagename -tag tagname

# 删除指定 tag 的指定镜像
nexus-cli image delete -name imagename -tag tagname

# 仅保留 n 项 tag，其余全部删除
nexus-cli image delete -name imagename -keep n

# -imagename 镜像名
# -keep n 表示保留几个tag
```

手动执行nexus任务清理空间

![](https://github.com/Xiao254182/Notes/blob/master/img/22/15.png)

### 5.磁盘拓展

使用 `lvextend` 和 `resize2fs/xfs_growfs` 来扩展逻辑卷，并确保 `sdb` 设备上的 100G 空间可以被 `centos-root` 和 `centos-home` 这两个逻辑卷使用。步骤如下：

#### 1. 确保 `/data` 目录下的数据已经迁移或备份

因为 `/dev/sdb` 目前已经挂载到 `/data`，如果 `/data` 没有重要数据，建议先卸载：

```shell
umount /data
```

#### 2. 删除 `/dev/sdb` 上的现有分区

**警告**：此操作会删除 `/dev/sdb` 上的所有数据，**请先确认 `/data` 目录下没有重要数据！**

```shell
fdisk /dev/sdb
```

在 `fdisk` 命令行中：

1. 输入 `d` 并按回车（删除当前分区）
2. 输入 `n` 并按回车（创建新分区）
3. 选择 `p`（创建主分区）
4. 选择分区编号 `1`
5. 直接回车（使用默认起始扇区）
6. 直接回车（使用全部 100G 空间）
7. 输入 `w` 并按回车（保存并退出）

#### 3. 创建 LVM 物理卷

```shell
pvcreate /dev/sdb1
```

#### 4. 将新分区加入 Volume Group

你的 `centos-root` 和 `centos-home` 都在 `centos` VG（Volume Group）下，所以先扩展 `centos` VG：

```shell
vgextend centos /dev/sdb1
```

#### 5. 扩展逻辑卷

##### (1) 扩展 `/` 逻辑卷（20G）

```shell
lvextend -L +20G /dev/mapper/centos-root
```

##### (2) 扩展 `/home` 逻辑卷（80G）

```shell
lvextend -L +80G /dev/mapper/centos-home
```

#### 6. 调整文件系统

如果 `/` 和 `/home` 使用的是 `xfs` 文件系统：

```shell
xfs_growfs /
xfs_growfs /home
```

如果使用 `ext4`，则执行：

```shell
resize2fs /dev/mapper/centos-root
resize2fs /dev/mapper/centos-home
```

#### 7. 确认扩展是否生效

```shell
df -h
```

扩展成功后，`/` 目录应增加 20G，`/home` 目录应增加 80G。

### 6.arm架构使用docker部署redis的问题

问题环境：

```shell
root@localhost:/data# hostnamectl 
   Static hostname: localhost
         Icon name: computer-vm
           Chassis: vm
        Machine ID: a80231de02fc4ece8db4ac48476084cc
           Boot ID: 5475319153c04803bb7fc33314b26f78
    Virtualization: kvm
  Operating System: UnionTech OS Server 20
            Kernel: Linux 4.19.0-arm64-server
      Architecture: arm64
```

使用

```shell
docker run -d --name redis --restart=always -p 6379:6379 redis:6
```

启动redis服务会报

```shell
1:C 10 Apr 2025 02:12:10.711 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo
1:C 10 Apr 2025 02:12:10.711 # Redis version=6.2.17, bits=64, commit=00000000, modified=0, pid=1, just started
1:C 10 Apr 2025 02:12:10.711 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.conf
1:M 10 Apr 2025 02:12:10.713 * monotonic clock: POSIX clock_gettime
1:M 10 Apr 2025 02:12:10.713 * Running mode=standalone, port=6379.
1:M 10 Apr 2025 02:12:10.713 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.
1:M 10 Apr 2025 02:12:10.713 # Server initialized
1:M 10 Apr 2025 02:12:10.714 # WARNING Your kernel has a bug that could lead to data corruption during background save. Please upgrade to the latest stable kernel.
1:M 10 Apr 2025 02:12:10.714 # Redis will now exit to prevent data corruption. Note that it is possible to suppress this warning by setting the following config: ignore-warnings ARM64-COW-BUG
```

这里有两个警告会导致redis容器无法启动
（1）与 `somaxconn` 相关

```shell
WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.
```

只需要调整 `somaxconn` 参数来避免这个警告。运行以下命令来调整系统的最大 TCP 连接数

```shell
# 临时调整
sysctl -w net.core.somaxconn=511

# 永久修改
echo "net.core.somaxconn=511" >> /etc/sysctl.conf && sysctl -p
```

（2）与内核相关的 bug

```shell
Redis will now exit to prevent data corruption. Note that it is possible to suppress this warning by setting the following config: ignore-warnings ARM64-COW-BUG
```

这通常是由于 ARM64 架构下的内核 bug 引起的。Redis 在启动时会自动检测到该问题，并在此情况下退出以防止数据损坏

解决方法一是升级内核

```shell
root@localhost:/data# sudo apt-get upgrade linux-image-$(uname -r)
正在读取软件包列表... 完成
正在分析软件包的依赖关系树       
正在读取状态信息... 完成       
linux-image-4.19.0-arm64-server 已经是最新版 (4.19.90-5070)。
```

但在这个环境下内核已经是最新的了，没法升级，后续只能看UOS对redis的兼容了

方法二就是在redis启动命令中忽略该警告，直接通过命令行传递参数即可

```shell
docker run -d --name redis --restart=always -p 6379:6379 redis:6 redis-server --ignore-warnings ARM64-COW-BUG
```

但这个方法可能会带来潜在的数据损坏风险

### 7.mysql8.0+重置root密码

修改配置文件，添加 skip-grant-table（跳过权限验证）

```shell
# 配置文件的地址按实际配置文件地址来

echo "skip-grant-table" >> /etc/my.cnf
```

重启MySQL

```shell
systemctl restart mysqld
```


然后就可以直接免密码登录了

```shell
mysql -u root -p
```

进入数据库后重置密码（MySQL8.0+版本与之前版本有所不同）

```shell
flush privileges;
use mysql;
update user set authentication_string='' where user='root';
ALTER user 'root'@'localhost' IDENTIFIED BY '<你的密码>';
```


关闭免密登陆

```shell
sed -i "s/skip-grant-table/#skip-grant-table/g" /etc/my.cnf
```

重启MySQL即可

(PS:此时你的root密码虽然被重置为新的密码了，但是通过命令也可以看到重置密码的方式是将之前的root密码改为空然后重新赋予新的密码，因此此时的root并没有远程登陆的账号可用

因此你可以添加远程登录权限

```shell
CREATE USER 'root'@'%' IDENTIFIED BY '<你的密码>';
GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' WITH GRANT OPTION;
FLUSH PRIVILEGES;
```

也可以修改现有的 root 记录

```shell
UPDATE mysql.user SET Host = '%' WHERE User = 'root' AND Host = 'localhost';
FLUSH PRIVILEGES;
```

但是 修改后将无法通过 `localhost` 登录 root，**强烈建议不要直接这样改**，而是新增一条 `root@%`，或新建一个远程用户

)
### 8.Socat 容器介绍和使用

`socat`（Socket CAT）是一个强大的网络工具，用于创建任意两个地址之间的双向数据通道。它可以桥接 TCP、UDP、UNIX sockets、文件、串口等各种通信端点，非常适合在容器化环境中用作**服务代理、中转、调试、端口映射**等用途。

---

#### 容器镜像

推荐使用镜像：

```bash
docker pull alpine/socat
```

该镜像基于 Alpine Linux，轻量且启动快速。

---

#### 常见用法示例与实际生产场景

##### 1. Web 服务透明代理（用于内网穿透）

```bash
socat tcp-listen:8080,fork,reuseaddr tcp-connect:www.example.com:80
```

**实际应用：** 在没有公网 IP 的开发环境中，开发人员通过 `socat` 将本地容器的请求转发到部署在外部测试环境中的 Web API（如测试版电商网站）。解决了测试人员无法直接访问外部资源的问题。

---

##### 2. SSH 暴露跳板

```bash
socat tcp-listen:10022,fork,reuseaddr tcp-connect:192.168.1.100:22
```

**实际应用：** 公司内网的运维跳板服务器不允许直接暴露端口，使用 `socat` 将容器内的 SSH 服务映射到宿主机指定端口，实现对某些内部资源的远程访问权限隔离。

---

##### 3. Redis 端口中继（跨 Docker 网络访问）

```bash
socat TCP-LISTEN:6380,fork,reuseaddr TCP:172.21.0.30:6379
```

**实际应用：** 在 CI/CD 流水线中构建的 Redis 容器运行于 isolated 网络，为便于临时容器访问缓存服务，使用 `socat` 中继端口，无需改变主网络配置，提升部署灵活性。

---

##### 4. UNIX Socket ↔ TCP 转发

```bash
socat TCP-LISTEN:8081,fork UNIX:/var/run/nginx.sock
```

**实际应用：** 多个服务通过本地 Unix socket 向 Nginx 提交请求，但某些工具或监控系统（如 Prometheus exporter）只支持 TCP 访问，因此通过 `socat` 转换协议，实现对 Nginx 的访问监控。

---

##### 5. 串口设备 ↔ TCP（物联网调试）

```bash
socat /dev/ttyUSB0,b9600 TCP-LISTEN:12345,reuseaddr,fork
```

**实际应用：** 在嵌入式开发中，为远程开发人员开放串口设备访问权限，用于调试 Arduino、树莓派或其他物联网网关设备的数据通信。无需物理连接，即可远程串口调试。

---

##### 6. 多目标端口复制（数据流分发）

```bash
socat -v TCP-LISTEN:9000,fork \
  SYSTEM:'tee >(socat - TCP:192.168.1.101:8001) | socat - TCP:192.168.1.102:8002'
```

**实际应用：** 某监控系统需要同时将业务日志流发送到日志分析平台（如 ELK）和实时告警系统（如 Prometheus + Alertmanager），通过 `socat + tee` 实现日志双向分发。

---

#### 简单端口代理示例：

##### 背景:

在生产环境中，MySQL 容器已通过端口 3306 暴露服务，但该容器所在的主机处于堡垒机后面，并且只开放了端口 30900。为了避免重新创建 MySQL 容器，我们希望通过 `socat` 创建一个代理容器，将外部访问的 30900 端口转发到 MySQL 容器的 3306 端口。这样，在连接到 VPN 后，用户就可以通过本地数据库客户端（如 Navicat）直接访问 MySQL。

##### 解决方案：

**MySQL 容器配置：**

这是已经在生产环境中运行的 MySQL 容器配置，暴露了 3306 端口供应用访问。

```yaml
mysql:
  image: mysql:8.0.27
  container_name: mysql
  networks:
    20_jnet:
      ipv4_address: 172.20.0.11
  ports:
    - "3306:3306"  # 容器内部端口3306映射到宿主机3306
  environment:
    MYSQL_ROOT_PASSWORD: 2ehw@2wqua%
    TZ: Asia/Shanghai
  volumes:
    - /mount/mysql/data:/var/lib/mysql
    - /mount/mysql/conf.d:/etc/mysql/conf.d
  command: >
    --default-authentication-plugin=mysql_native_password
    --character-set-server=utf8mb4
    --collation-server=utf8mb4_unicode_ci
    --lower_case_table_names=1
  restart: always
```

**通过 `socat` 创建代理容器：**

通过 `socat` 工具，我们可以创建一个代理容器，使得访问宿主机的 30900 端口实际上会转发到 MySQL 容器的 3306 端口。这样，通过连接到 VPN 后，用户即可直接在本地客户端（如 Navicat）使用 `localhost:30900` 访问数据库。

启动 `socat` 代理容器的命令如下：

```bash
docker run -d \
  --name mysql-proxy \
  --network 20_jnet \ # 加入到同样的docker内部网络中
  --ip 172.20.0.50 \
  -p 30900:30900 \  # 将宿主机的30900端口映射到容器的30900端口
  --restart always \
  alpine/socat \
  tcp-listen:30900,fork,reuseaddr \
  tcp-connect:172.20.0.11:3306  # 将流量转发到mysql容器的3306端口
```

- `-p 30900:30900`：将宿主机的 30900 端口映射到容器的 30900 端口。
- `tcp-listen:30900,fork,reuseaddr`：监听宿主机的 30900 端口，`fork` 表示每个连接请求都创建一个新进程，`reuseaddr` 允许地址重用。
- `tcp-connect:172.20.0.11:3306`：将请求转发到 `mysql` 容器的 3306 端口。

##### 说明

- 访问宿主机的 30900 端口，相当于直接访问 MySQL 容器的 3306 端口。
- 在 VPN 连接后，你可以通过 Navicat 或其他 MySQL 客户端使用 `localhost:30900` 连接到数据库，而无需直接访问 MySQL 容器的端口。

---

#### 注意事项

- 容器之间推荐使用自定义 Docker 网络（如 bridge 类型）实现内网互通。
- `socat` 不支持加密和认证，不建议直接暴露在公网中使用。
- 适合用于信任网络内的服务代理、测试验证或工具链集成。
